{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done By: **Ryan Yeo**\n",
    "\n",
    "Class: **DAAA/FT/1B/01**\n",
    "\n",
    "Admin Num: **P2214452**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'datasets_cleaned'\n"
     ]
    }
   ],
   "source": [
    "# Create directory if it exists print err\n",
    "try:\n",
    "    os.mkdir('datasets_cleaned')\n",
    "except OSError as error:\n",
    "    print(error)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean employment dataset\n",
    "\n",
    "# Note:\n",
    "# We cannot use genfromtxt directly because it reads commas contained in strings(unlike csvreader and pd.read_csv) \n",
    "# To avoid that, we first read in all the data seperated by a newline before processing it\n",
    "\n",
    "dirtyData_17to19 = np.genfromtxt('datasets_src/employment/emp_17to19.csv', dtype=\"U64\",delimiter=\"\\n\")\n",
    "dirtyData_19to21 = np.genfromtxt('datasets_src/employment/emp_19to21.csv', dtype=\"U64\",delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and clean the dataset so that it can be written to datasets_cleaned\n",
    "def cleanData(dirtyArr):\n",
    "    employ_arr = []\n",
    "    for i in dirtyArr:\n",
    "        _ = []\n",
    "        inQuotes = False\n",
    "        for j,n in enumerate(i):\n",
    "            if n=='\\\"':\n",
    "                # If opening quotes => True elif closing quotes => False\n",
    "                inQuotes=not inQuotes\n",
    "            if n==',' and inQuotes:\n",
    "                # If it's used in a string, change it to a backtick\n",
    "                # This is for the sole purpose of not causing any error when reading as csv\n",
    "                # When printing from this column, backticks will be changed back to commas\n",
    "                if i[j+1]==' ':\n",
    "                    _.append('`')\n",
    "                # If it's used in money, (e.g. $3,600) just remove the comma\n",
    "                else:\n",
    "                    _.append('')\n",
    "            else:\n",
    "                _.append(n)\n",
    "        employ_arr.append(\"\".join(_))\n",
    "    employ_arr = np.array(employ_arr)\n",
    "    return employ_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can delete one set of 2019 data since we don't need duplicates from both arr\n",
    "cleaned_17to19 = cleanData(dirtyData_17to19)[:-((len(cleanData(dirtyData_17to19))-1)//3)]\n",
    "\n",
    "# We can also delete the header for the second arr\n",
    "cleaned_19to21 = cleanData(dirtyData_19to21)[1:]\n",
    "\n",
    "cleaned = np.concatenate((cleaned_17to19,cleaned_19to21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'datasets_cleaned/employment'\n"
     ]
    }
   ],
   "source": [
    "# Now we can write back the data into datasets_cleaned\n",
    "try:\n",
    "    os.mkdir('datasets_cleaned/employment')\n",
    "except OSError as error:\n",
    "    print(error)  \n",
    "\n",
    "cleaned.tofile('datasets_cleaned/employment/employ.csv',sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However at this point our data is still not in the right format yet\n",
    "\n",
    "Due to our need to manipulate and remove commas that were not seperators, \n",
    "we had to cast each row as a string datatype\n",
    "\n",
    "When writing to a csv file, it will cause quotation marks to appear for each row\n",
    "Since we don't want that to affect main.ipynb, we would have to reopen the file the format it\n",
    "\n",
    "This time since we changed the commas, it would be less of a hassle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='U64',delimiter=',')\n",
    "# Reformat array\n",
    "f = np.char.replace(f,'\\'','')  \n",
    "f = np.char.replace(f,'\\\"','')\n",
    "\n",
    "# We can also remove the '$' and the '%' in the meantime so that we can easily convert into float later\n",
    "f = np.char.replace(f,'$','')\n",
    "f = np.char.replace(f,'%','')\n",
    "\n",
    "\n",
    "# Delete file so that savetxt does not replace chars\n",
    "os.remove('datasets_cleaned/employment/employ.csv')\n",
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/employment/employ.csv',f,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake\n",
    "Now we repeat the entire process again for the different intakes (_This includes Poly and Uni_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior to this, U64 was used and it accidentally cut off data from Poly Intake\n",
    "dirtyPoly = np.genfromtxt('datasets_src/poly_intake/polytechnics-intake-enrolment-and-graduates-by-course.csv', dtype=\"U128\",delimiter=\"\\n\")\n",
    "dirtyUni = np.genfromtxt('datasets_src/uni_intake/universities-intake-enrolment-and-graduates-by-course.csv',dtype=\"U128\",delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is no salary data, we are just replacing commas with backticks using cleanData\n",
    "cleanPoly = cleanData(dirtyPoly)\n",
    "cleanUni = cleanData(dirtyUni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'datasets_cleaned/poly'\n"
     ]
    }
   ],
   "source": [
    "# Poly\n",
    "try:\n",
    "    os.mkdir('datasets_cleaned/poly')\n",
    "except OSError as error:\n",
    "    print(error)  \n",
    "\n",
    "# Generates an error if you already have the file opened elsewhere\n",
    "cleanPoly.tofile('datasets_cleaned/poly/poly_intake.csv',sep='\\n')\n",
    "\n",
    "# Since now each string is one cell of data and not one row, we can go back to using U64\n",
    "f=np.genfromtxt('datasets_cleaned/poly/poly_intake.csv',dtype='U64',delimiter=',')\n",
    "# Reformat array\n",
    "f = np.char.replace(f,'\\'','')  \n",
    "f = np.char.replace(f,'\\\"','')\n",
    "\n",
    "# Delete file so that savetxt does not replace chars\n",
    "os.remove('datasets_cleaned/poly/poly_intake.csv')\n",
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/poly/poly_intake.csv',f,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'datasets_cleaned/uni'\n"
     ]
    }
   ],
   "source": [
    "# Uni\n",
    "try:\n",
    "    os.mkdir('datasets_cleaned/uni')\n",
    "except OSError as error:\n",
    "    print(error)  \n",
    "\n",
    "# Generates an error if you already have the file opened elsewhere\n",
    "cleanUni.tofile('datasets_cleaned/uni/uni_intake.csv',sep='\\n')\n",
    "\n",
    "f=np.genfromtxt('datasets_cleaned/uni/uni_intake.csv',dtype='U64',delimiter=',')\n",
    "# Reformat array\n",
    "f = np.char.replace(f,'\\'','')  \n",
    "f = np.char.replace(f,'\\\"','')\n",
    "\n",
    "# Delete file so that savetxt does not replace chars\n",
    "os.remove('datasets_cleaned/uni/uni_intake.csv')\n",
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/uni/uni_intake.csv',f,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "employEdit = np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='U64',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our employment datasets are from MOE and our intake datasets are from [data.gov.sg](https://www.data.gov.sg/group/education), it is best to rename the column names from both datasets so that it is easier for comparison later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Initial Col Name   | New Col Name |\n",
    "|----------------------|------|\n",
    "| Engineering | Engineering |\n",
    "| Architecture | Architecture and Built Environment|\n",
    "| Business | Business |\n",
    "| Information & Digital Technologies | Information & Digital Technologies|\n",
    "| Medicine | Medicine |\n",
    "| Arts, Design & Medias | Arts, Humanities and the Social Sciences|\n",
    "| Dentistry | Dentistry |\n",
    "| Built environment | Architecture and Built Environment|\n",
    "|Yale-NUS| *Removed*|\n",
    "|Biomedical Sciences| Health Sciences |\n",
    "| Pharmacy | Health Sciences |\n",
    "| Education (NIE) | Education |\n",
    "| Music | Arts, Humanities and the Social Sciences|\n",
    "| Humanities & Social Sciences | Arts, Humanities and the Social Sciences|\n",
    "| Health Sciences | Health Sciences |\n",
    "| Sciences | Sciences |\n",
    "| Law | Law |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['year' 'course_cluster' 'employed' 'ft_employment'\n",
      "  'gross median salary']\n",
      " ['2017' 'Arts` Humanities and the Social Sciences' '91.40' '65.60'\n",
      "  '2944']\n",
      " ['2017' 'Architecture and Built Environment' '92.70' '86.50' '3200']\n",
      " ['2017' 'Business' '95.40' '89.50' '3200']\n",
      " ['2017' 'Dentistry' '100' '100.00' '4050']\n",
      " ['2017' 'Education' '100' '100.00' '3600']\n",
      " ['2017' 'Engineering' '86.70' '79.50' '3500']\n",
      " ['2017' 'Health Sciences' '96.70' '93.70' '3450']\n",
      " ['2017' 'Arts` Humanities and the Social Sciences' '85.70' '70.10'\n",
      "  '3300']\n",
      " ['2017' 'Information & Digital Technologies' '94.60' '90.10' '4000']\n",
      " ['2017' 'Arts` Humanities and the Social Sciences' '73.30' '26.70'\n",
      "  '2225']\n",
      " ['2017' 'Sciences' '82.60' '65.30' '3250']\n",
      " ['2017' 'Architecture and Built Environment' '91.30' '86.40' '4000']\n",
      " ['2017' 'Health Sciences' '92.00' '80.00' '2950']\n",
      " ['2017' 'Law' '96.40' '92.80' '5000']\n",
      " ['2017' 'Medicine' '100.00' '100.00' '5000']\n",
      " ['2017' 'Health Sciences' '99.10' '94.50' '3600']\n",
      " ['2018' 'Arts` Humanities and the Social Sciences' '89.10' '68.30'\n",
      "  '3000']\n",
      " ['2018' 'Architecture and Built Environment' '91.60' '85.90' '3400']\n",
      " ['2018' 'Business' '94.40' '89.10' '3400']\n",
      " ['2018' 'Dentistry' '100.00' '100.00' '4050']\n",
      " ['2018' 'Education' '100.00' '99.40' '3800']\n",
      " ['2018' 'Engineering' '89.90' '83.80' '3600']\n",
      " ['2018' 'Health Sciences' '96.70' '89.40' '3450']\n",
      " ['2018' 'Arts` Humanities and the Social Sciences' '87.30' '72.10'\n",
      "  '3400']\n",
      " ['2018' 'Information & Digital Technologies' '95.00' '92.00' '4022']\n",
      " ['2018' 'Arts` Humanities and the Social Sciences' '81.00' '23.80'\n",
      "  '1800']\n",
      " ['2018' 'Sciences' '84.40' '68.80' '3313']\n",
      " ['2018' 'Architecture and Built Environment' '96.20' '92.40' '4000']\n",
      " ['2018' 'Health Sciences' '90.90' '81.80' '3000']\n",
      " ['2018' 'Law' '95.30' '91.80' '5000']\n",
      " ['2018' 'Medicine' 'NA' 'NA' 'NA']\n",
      " ['2018' 'Health Sciences' '96.60' '93.20' '3650']\n",
      " ['2019' 'Arts` Humanities and the Social Sciences' '87.30' '62.40'\n",
      "  '3200']\n",
      " ['2019' 'Architecture and Built Environment' '92.60' '87.30' '3500']\n",
      " ['2019' 'Business' '94.60' '88.80' '3500']\n",
      " ['2019' 'Dentistry' '100' '97.30' '4200']\n",
      " ['2019' 'Education' '100' '100.00' '3800']\n",
      " ['2019' 'Engineering' '88.40' '83.30' '3750']\n",
      " ['2019' 'Health Sciences' '97.10' '88.40' '3500']\n",
      " ['2019' 'Arts` Humanities and the Social Sciences' '88.00' '74.50'\n",
      "  '3500']\n",
      " ['2019' 'Information & Digital Technologies' '95.40' '92.70' '4400']\n",
      " ['2019' 'Arts` Humanities and the Social Sciences' '82.60' '39.10'\n",
      "  '3500']\n",
      " ['2019' 'Sciences' '86.90' '71.50' '3500']\n",
      " ['2019' 'Architecture and Built Environment' '100.00' '96.00' '4100']\n",
      " ['2019' 'Health Sciences' '95.20' '85.70' '3000']\n",
      " ['2019' 'Law' '97.00' '95.00' '5000']\n",
      " ['2019' 'Medicine' '99.60' '99.60' '5300']\n",
      " ['2019' 'Health Sciences' '100' '95.50' '3750']\n",
      " ['2020' 'Arts` Humanities and the Social Sciences' '92.30' '50.10'\n",
      "  '3300']\n",
      " ['2020' 'Architecture and Built Environment' '93.90' '72.50' '3500']\n",
      " ['2020' 'Business' '95.30' '76.00' '3500']\n",
      " ['2020' 'Dentistry' '100.00' '100.00' '4200']\n",
      " ['2020' 'Education' '100.00' '99.10' '3800']\n",
      " ['2020' 'Engineering' '93.60' '71.60' '3900']\n",
      " ['2020' 'Health Sciences' '97.40' '83.30' '3500']\n",
      " ['2020' 'Arts` Humanities and the Social Sciences' '92.10' '61.80'\n",
      "  '3500']\n",
      " ['2020' 'Information & Digital Technologies' '94.80' '87.30' '4760']\n",
      " ['2020' 'Arts` Humanities and the Social Sciences' '69.20' '15.40'\n",
      "  '3275']\n",
      " ['2020' 'Sciences' '91.60' '55.40' '3500']\n",
      " ['2020' 'Architecture and Built Environment' '94.00' '91.00' '4000']\n",
      " ['2020' 'Health Sciences' '94.70' '84.20' '3000']\n",
      " ['2020' 'Law' '93.40' '88.60' '5000']\n",
      " ['2020' 'Medicine' '100.00' '100.00' '5250']\n",
      " ['2020' 'Health Sciences' '99.30' '93.70' '3700']\n",
      " ['2021' 'Arts` Humanities and the Social Sciences' '92.60' '69.30'\n",
      "  '3500']\n",
      " ['2021' 'Architecture and Built Environment' '94.50' '88.90' '3600']\n",
      " ['2021' 'Business' '97.00' '88.70' '3723']\n",
      " ['2021' 'Dentistry' '100.00' '100.00' '4200']\n",
      " ['2021' 'Education' '100.00' '100.00' '3798']\n",
      " ['2021' 'Engineering' '94.00' '86.90' '3900']\n",
      " ['2021' 'Health Sciences' '95.70' '85.90' '3635']\n",
      " ['2021' 'Arts` Humanities and the Social Sciences' '91.20' '75.60'\n",
      "  '3550']\n",
      " ['2021' 'Information & Digital Technologies' '97.80' '93.70' '5000']\n",
      " ['2021' 'Arts` Humanities and the Social Sciences' '82.40' '35.30'\n",
      "  '3100']\n",
      " ['2021' 'Sciences' '91.70' '75.80' '3600']\n",
      " ['2021' 'Architecture and Built Environment' '97.70' '96.60' '4000']\n",
      " ['2021' 'Health Sciences' '90.90' '77.30' '3100']\n",
      " ['2021' 'Law' '97.90' '95.50' '5600']\n",
      " ['2021' 'Medicine' 'NA' 'NA' 'NA']\n",
      " ['2021' 'Health Sciences' '95.90' '91.90' '3915']]\n"
     ]
    }
   ],
   "source": [
    "# Rename course name to match the other datasets\n",
    "for a in employEdit:\n",
    "    if a[1]=='Architecture' or a[1]=='Built Environment':\n",
    "        a[1] = 'Architecture and Built Environment'\n",
    "    elif a[1]=='Arts` Design & Media' or a[1]=='Music' or a[1]=='Humanities & Social Sciences':\n",
    "        a[1] = 'Arts` Humanities and the Social Sciences'\n",
    "    elif a[1]=='Biomedical Sciences' or a[1]=='Pharmacy' or a[1]=='Health Sciences':\n",
    "        a[1] = 'Health Sciences'\n",
    "    elif a[1] == 'Education(NIE)':\n",
    "        a[1] = 'Education'\n",
    "\n",
    "# Remove row if it contains Yale-NUS\n",
    "counter=0\n",
    "for i,a in enumerate(employEdit):\n",
    "    if a[1]=='Yale-NUS':\n",
    "        employEdit = np.delete(employEdit,i-counter,0)\n",
    "        counter+=1\n",
    "\n",
    "print(employEdit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/employment/employ.csv',employEdit,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course cluster: Medicine, year: 2018, column: employed\n",
      "course cluster: Medicine, year: 2018, column: ft_employment\n",
      "course cluster: Medicine, year: 2018, column: gross median salary\n",
      "course cluster: Medicine, year: 2021, column: employed\n",
      "course cluster: Medicine, year: 2021, column: ft_employment\n",
      "course cluster: Medicine, year: 2021, column: gross median salary\n"
     ]
    }
   ],
   "source": [
    "# Read csv file\n",
    "employArr = np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='float',delimiter=',',skip_header=1,usecols=(0,2,3,4))\n",
    "col_header = np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='U64',delimiter=',',usecols=(0,2,3,4))[0]\n",
    "employCourse = np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='U64',delimiter=',',skip_header=1,usecols=(1))\n",
    "# Since we have to use isnan, setting names=True is not an option since the string cannot be set to float\n",
    "# As such we make our own artificial columns using dictionary and 'col_header'\n",
    "employNames = {}\n",
    "for i,n in enumerate(col_header):\n",
    "    employNames[n]=i\n",
    "\n",
    "# Get all missing data\n",
    "missing = np.argwhere(np.isnan(employArr))\n",
    "for i in missing:\n",
    "# Get col name by swapping key and values inside employNames\n",
    "    print(f\"course cluster: {employCourse[i[0]]}, year: {int(employArr[i[0]][0])}, column: {({v:k for k,v in employNames.items()})[i[1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the missing data is for the course cluster \"Medicine\" and for year 2018 and 2021\n",
    "\n",
    "Since:\n",
    "1. The missing data is not randomly distributed (its just for medicine)\n",
    "2. They are accounted for by other data in our datasets (Medicine data of salary and employment percentages from year 2017, 2019 and 2021 are likely to be similar to 2017,2019 and 2020)\n",
    "\n",
    "The missing data is Missing At Random\n",
    "\n",
    "*In the PDF by MOE, it is explained that the missing data is due to insufficient graduates/response rate*\n",
    "\n",
    "Since the data is MAR, we can either choose to impute or remove the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 100.   100.  5000.    99.6   99.6 5300.   100.   100.  5250. ]\n",
      "[2018.     99.87   99.87 5183.33]\n",
      "[2021.     99.87   99.87 5183.33]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Mean imputation\n",
    "\n",
    "# Get data for medicine from 2017,2019 and 2021\n",
    "dataForImpute = np.array([])\n",
    "for i,j in zip(employArr,employCourse):\n",
    "    if i[employNames[\"year\"]] in [2017,2019,2020] and j=='Medicine':\n",
    "        dataForImpute = np.concatenate((dataForImpute,i[1:]))\n",
    "\n",
    "print(dataForImpute)\n",
    "\n",
    "ImputeData = np.zeros((3,3))\n",
    "\n",
    "# Reformat data(by grouping similar cols together) so that np.mean() can be used\n",
    "for iter in range(3):\n",
    "    ImputeData[iter] = np.array([n for i,n in enumerate(dataForImpute) if i%3==iter])\n",
    "\n",
    "# Replace nan values with mean\n",
    "for i,n in enumerate(ImputeData):\n",
    "    employArr[missing[0][0]][i+1] = round(n.mean(),2)\n",
    "    employArr[missing[3][0]][i+1] = round(n.mean(),2)\n",
    "\n",
    "print(employArr[missing[0][0]])\n",
    "print(employArr[missing[3][0]])\n",
    "\n",
    "# If imputation was done correctly, the value of this should be 0\n",
    "print(len(np.argwhere(np.isnan(employArr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['year' 'course_cluster' 'employed' 'ft_employment'\n",
      "  'gross median salary']\n",
      " ['2017.0' 'Arts` Humanities and the Social Sciences' '91.4' '65.6'\n",
      "  '2944.0']\n",
      " ['2017.0' 'Architecture and Built Environment' '92.7' '86.5' '3200.0']\n",
      " ['2017.0' 'Business' '95.4' '89.5' '3200.0']\n",
      " ['2017.0' 'Dentistry' '100.0' '100.0' '4050.0']\n",
      " ['2017.0' 'Education' '100.0' '100.0' '3600.0']\n",
      " ['2017.0' 'Engineering' '86.7' '79.5' '3500.0']\n",
      " ['2017.0' 'Health Sciences' '96.7' '93.7' '3450.0']\n",
      " ['2017.0' 'Arts` Humanities and the Social Sciences' '85.7' '70.1'\n",
      "  '3300.0']\n",
      " ['2017.0' 'Information & Digital Technologies' '94.6' '90.1' '4000.0']\n",
      " ['2017.0' 'Arts` Humanities and the Social Sciences' '73.3' '26.7'\n",
      "  '2225.0']\n",
      " ['2017.0' 'Sciences' '82.6' '65.3' '3250.0']\n",
      " ['2017.0' 'Architecture and Built Environment' '91.3' '86.4' '4000.0']\n",
      " ['2017.0' 'Health Sciences' '92.0' '80.0' '2950.0']\n",
      " ['2017.0' 'Law' '96.4' '92.8' '5000.0']\n",
      " ['2017.0' 'Medicine' '100.0' '100.0' '5000.0']\n",
      " ['2017.0' 'Health Sciences' '99.1' '94.5' '3600.0']\n",
      " ['2018.0' 'Arts` Humanities and the Social Sciences' '89.1' '68.3'\n",
      "  '3000.0']\n",
      " ['2018.0' 'Architecture and Built Environment' '91.6' '85.9' '3400.0']\n",
      " ['2018.0' 'Business' '94.4' '89.1' '3400.0']\n",
      " ['2018.0' 'Dentistry' '100.0' '100.0' '4050.0']\n",
      " ['2018.0' 'Education' '100.0' '99.4' '3800.0']\n",
      " ['2018.0' 'Engineering' '89.9' '83.8' '3600.0']\n",
      " ['2018.0' 'Health Sciences' '96.7' '89.4' '3450.0']\n",
      " ['2018.0' 'Arts` Humanities and the Social Sciences' '87.3' '72.1'\n",
      "  '3400.0']\n",
      " ['2018.0' 'Information & Digital Technologies' '95.0' '92.0' '4022.0']\n",
      " ['2018.0' 'Arts` Humanities and the Social Sciences' '81.0' '23.8'\n",
      "  '1800.0']\n",
      " ['2018.0' 'Sciences' '84.4' '68.8' '3313.0']\n",
      " ['2018.0' 'Architecture and Built Environment' '96.2' '92.4' '4000.0']\n",
      " ['2018.0' 'Health Sciences' '90.9' '81.8' '3000.0']\n",
      " ['2018.0' 'Law' '95.3' '91.8' '5000.0']\n",
      " ['2018.0' 'Medicine' '99.87' '99.87' '5183.33']\n",
      " ['2018.0' 'Health Sciences' '96.6' '93.2' '3650.0']\n",
      " ['2019.0' 'Arts` Humanities and the Social Sciences' '87.3' '62.4'\n",
      "  '3200.0']\n",
      " ['2019.0' 'Architecture and Built Environment' '92.6' '87.3' '3500.0']\n",
      " ['2019.0' 'Business' '94.6' '88.8' '3500.0']\n",
      " ['2019.0' 'Dentistry' '100.0' '97.3' '4200.0']\n",
      " ['2019.0' 'Education' '100.0' '100.0' '3800.0']\n",
      " ['2019.0' 'Engineering' '88.4' '83.3' '3750.0']\n",
      " ['2019.0' 'Health Sciences' '97.1' '88.4' '3500.0']\n",
      " ['2019.0' 'Arts` Humanities and the Social Sciences' '88.0' '74.5'\n",
      "  '3500.0']\n",
      " ['2019.0' 'Information & Digital Technologies' '95.4' '92.7' '4400.0']\n",
      " ['2019.0' 'Arts` Humanities and the Social Sciences' '82.6' '39.1'\n",
      "  '3500.0']\n",
      " ['2019.0' 'Sciences' '86.9' '71.5' '3500.0']\n",
      " ['2019.0' 'Architecture and Built Environment' '100.0' '96.0' '4100.0']\n",
      " ['2019.0' 'Health Sciences' '95.2' '85.7' '3000.0']\n",
      " ['2019.0' 'Law' '97.0' '95.0' '5000.0']\n",
      " ['2019.0' 'Medicine' '99.6' '99.6' '5300.0']\n",
      " ['2019.0' 'Health Sciences' '100.0' '95.5' '3750.0']\n",
      " ['2020.0' 'Arts` Humanities and the Social Sciences' '92.3' '50.1'\n",
      "  '3300.0']\n",
      " ['2020.0' 'Architecture and Built Environment' '93.9' '72.5' '3500.0']\n",
      " ['2020.0' 'Business' '95.3' '76.0' '3500.0']\n",
      " ['2020.0' 'Dentistry' '100.0' '100.0' '4200.0']\n",
      " ['2020.0' 'Education' '100.0' '99.1' '3800.0']\n",
      " ['2020.0' 'Engineering' '93.6' '71.6' '3900.0']\n",
      " ['2020.0' 'Health Sciences' '97.4' '83.3' '3500.0']\n",
      " ['2020.0' 'Arts` Humanities and the Social Sciences' '92.1' '61.8'\n",
      "  '3500.0']\n",
      " ['2020.0' 'Information & Digital Technologies' '94.8' '87.3' '4760.0']\n",
      " ['2020.0' 'Arts` Humanities and the Social Sciences' '69.2' '15.4'\n",
      "  '3275.0']\n",
      " ['2020.0' 'Sciences' '91.6' '55.4' '3500.0']\n",
      " ['2020.0' 'Architecture and Built Environment' '94.0' '91.0' '4000.0']\n",
      " ['2020.0' 'Health Sciences' '94.7' '84.2' '3000.0']\n",
      " ['2020.0' 'Law' '93.4' '88.6' '5000.0']\n",
      " ['2020.0' 'Medicine' '100.0' '100.0' '5250.0']\n",
      " ['2020.0' 'Health Sciences' '99.3' '93.7' '3700.0']\n",
      " ['2021.0' 'Arts` Humanities and the Social Sciences' '92.6' '69.3'\n",
      "  '3500.0']\n",
      " ['2021.0' 'Architecture and Built Environment' '94.5' '88.9' '3600.0']\n",
      " ['2021.0' 'Business' '97.0' '88.7' '3723.0']\n",
      " ['2021.0' 'Dentistry' '100.0' '100.0' '4200.0']\n",
      " ['2021.0' 'Education' '100.0' '100.0' '3798.0']\n",
      " ['2021.0' 'Engineering' '94.0' '86.9' '3900.0']\n",
      " ['2021.0' 'Health Sciences' '95.7' '85.9' '3635.0']\n",
      " ['2021.0' 'Arts` Humanities and the Social Sciences' '91.2' '75.6'\n",
      "  '3550.0']\n",
      " ['2021.0' 'Information & Digital Technologies' '97.8' '93.7' '5000.0']\n",
      " ['2021.0' 'Arts` Humanities and the Social Sciences' '82.4' '35.3'\n",
      "  '3100.0']\n",
      " ['2021.0' 'Sciences' '91.7' '75.8' '3600.0']\n",
      " ['2021.0' 'Architecture and Built Environment' '97.7' '96.6' '4000.0']\n",
      " ['2021.0' 'Health Sciences' '90.9' '77.3' '3100.0']\n",
      " ['2021.0' 'Law' '97.9' '95.5' '5600.0']\n",
      " ['2021.0' 'Medicine' '99.87' '99.87' '5183.33']\n",
      " ['2021.0' 'Health Sciences' '95.9' '91.9' '3915.0']]\n"
     ]
    }
   ],
   "source": [
    "# Combine everything back together\n",
    "tmp = np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='U64',delimiter=',')[0]\n",
    "employ = np.vstack((tmp, np.column_stack((employArr[:,0],employCourse,employArr[:,1:]))))\n",
    "print(employ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "Architecture and Built Environment [2, 12]\n",
      "['2017.0' 'Architecture and Built Environment' '91.3' '86.4' '4000.0'] 1\n",
      "['2017.0' 'Architecture and Built Environment' '92.0' '86.45' '3600.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [1, 8, 10]\n",
      "['2017.0' 'Arts` Humanities and the Social Sciences' '85.7' '70.1'\n",
      " '3300.0'] 1\n",
      "['2017.0' 'Arts` Humanities and the Social Sciences' '73.3' '26.7'\n",
      " '2225.0'] 2\n",
      "['2017.0' 'Arts` Humanities and the Social Sciences' '83.47' '54.13'\n",
      " '2823.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Health Sciences [7, 13, 16]\n",
      "['2017.0' 'Health Sciences' '92.0' '80.0' '2950.0'] 1\n",
      "['2017.0' 'Health Sciences' '99.1' '94.5' '3600.0'] 2\n",
      "['2017.0' 'Health Sciences' '95.93' '89.4' '3333.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Architecture and Built Environment [18, 28]\n",
      "['2018.0' 'Architecture and Built Environment' '96.2' '92.4' '4000.0'] 1\n",
      "['2018.0' 'Architecture and Built Environment' '93.9' '89.15' '3700.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [17, 24, 26]\n",
      "['2018.0' 'Arts` Humanities and the Social Sciences' '87.3' '72.1'\n",
      " '3400.0'] 1\n",
      "['2018.0' 'Arts` Humanities and the Social Sciences' '81.0' '23.8'\n",
      " '1800.0'] 2\n",
      "['2018.0' 'Arts` Humanities and the Social Sciences' '85.8' '54.73'\n",
      " '2733.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Health Sciences [23, 29, 32]\n",
      "['2018.0' 'Health Sciences' '90.9' '81.8' '3000.0'] 1\n",
      "['2018.0' 'Health Sciences' '96.6' '93.2' '3650.0'] 2\n",
      "['2018.0' 'Health Sciences' '94.73' '88.13' '3367.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Architecture and Built Environment [34, 44]\n",
      "['2019.0' 'Architecture and Built Environment' '100.0' '96.0' '4100.0'] 1\n",
      "['2019.0' 'Architecture and Built Environment' '96.3' '91.65' '3800.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [33, 40, 42]\n",
      "['2019.0' 'Arts` Humanities and the Social Sciences' '88.0' '74.5'\n",
      " '3500.0'] 1\n",
      "['2019.0' 'Arts` Humanities and the Social Sciences' '82.6' '39.1'\n",
      " '3500.0'] 2\n",
      "['2019.0' 'Arts` Humanities and the Social Sciences' '85.97' '58.67'\n",
      " '3400.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Health Sciences [39, 45, 48]\n",
      "['2019.0' 'Health Sciences' '95.2' '85.7' '3000.0'] 1\n",
      "['2019.0' 'Health Sciences' '100.0' '95.5' '3750.0'] 2\n",
      "['2019.0' 'Health Sciences' '97.43' '89.87' '3417.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Architecture and Built Environment [50, 60]\n",
      "['2020.0' 'Architecture and Built Environment' '94.0' '91.0' '4000.0'] 1\n",
      "['2020.0' 'Architecture and Built Environment' '93.95' '81.75' '3750.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [49, 56, 58]\n",
      "['2020.0' 'Arts` Humanities and the Social Sciences' '92.1' '61.8'\n",
      " '3500.0'] 1\n",
      "['2020.0' 'Arts` Humanities and the Social Sciences' '69.2' '15.4'\n",
      " '3275.0'] 2\n",
      "['2020.0' 'Arts` Humanities and the Social Sciences' '84.53' '42.43'\n",
      " '3358.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Health Sciences [55, 61, 64]\n",
      "['2020.0' 'Health Sciences' '94.7' '84.2' '3000.0'] 1\n",
      "['2020.0' 'Health Sciences' '99.3' '93.7' '3700.0'] 2\n",
      "['2020.0' 'Health Sciences' '97.13' '87.07' '3400.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Architecture and Built Environment [66, 76]\n",
      "['2021.0' 'Architecture and Built Environment' '97.7' '96.6' '4000.0'] 1\n",
      "['2021.0' 'Architecture and Built Environment' '96.1' '92.75' '3800.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [65, 72, 74]\n",
      "['2021.0' 'Arts` Humanities and the Social Sciences' '91.2' '75.6'\n",
      " '3550.0'] 1\n",
      "['2021.0' 'Arts` Humanities and the Social Sciences' '82.4' '35.3'\n",
      " '3100.0'] 2\n",
      "['2021.0' 'Arts` Humanities and the Social Sciences' '88.73' '60.07'\n",
      " '3383.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Health Sciences [71, 77, 80]\n",
      "['2021.0' 'Health Sciences' '90.9' '77.3' '3100.0'] 1\n",
      "['2021.0' 'Health Sciences' '95.9' '91.9' '3915.0'] 2\n",
      "['2021.0' 'Health Sciences' '94.17' '85.03' '3550.0']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA']\n"
     ]
    }
   ],
   "source": [
    "# Combine intakes,enrollment and graduation data for courses that were group similarly\n",
    "\n",
    "# Start by getting a unique set of all the courses\n",
    "unique_courses = np.unique(employCourse)\n",
    "\n",
    "# Amount of rows we should have at the end (+1 for header)\n",
    "print(len(unique_courses)*(2022-2017))\n",
    "\n",
    "# Add the data to the dictionary\n",
    "for year in range(2017,2022):\n",
    "    \n",
    "    # Create a dictionary to store the data\n",
    "    course_dict = {}\n",
    "    for course in unique_courses:\n",
    "        course_dict[course] = []\n",
    "\n",
    "    for i,a in enumerate(employ):\n",
    "        if a[1] in course_dict and float(a[0])==year:\n",
    "            course_dict[a[1]].append(i)\n",
    "\n",
    "    for k,v in course_dict.items():\n",
    "        if len(v)>1:\n",
    "            print(k,v)\n",
    "            for j,n in enumerate(v):\n",
    "                # Combine the data into one numpy array\n",
    "                if j>0:\n",
    "                    print(employ[n],j)\n",
    "                    employ[v[0]][2] = str(float(employ[v[0]][2])+float(employ[n][2]))\n",
    "                    employ[v[0]][3] = str(float(employ[v[0]][3])+float(employ[n][3]))\n",
    "                    employ[v[0]][4] = str(float(employ[v[0]][4])+float(employ[n][4]))\n",
    "\n",
    "\n",
    "                    # Remove the duplicates later\n",
    "                    employ[n] = np.array(['NA','NA','NA','NA','NA'])\n",
    "            \n",
    "            # Get average\n",
    "            employ[v[0]][2] = str(round(float(employ[v[0]][2])/len(v),2))\n",
    "            employ[v[0]][3] = str(round(float(employ[v[0]][3])/len(v),2))\n",
    "            employ[v[0]][4] = str(round(float(employ[v[0]][4])/len(v),0))\n",
    "            \n",
    "            for n in v:\n",
    "                print(employ[n])\n",
    "    year+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all NA\n",
    "# employ[:,0]!='NA' checks the first col in every row (returns True if not NA)\n",
    "employ = employ[employ[:,0]!='NA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['year' 'course_cluster' 'employed' 'ft_employment'\n",
      "  'gross median salary']\n",
      " ['2017' 'Arts` Humanities and the Social Sciences' '83.47' '54.13'\n",
      "  '2823']\n",
      " ['2017' 'Architecture and Built Environment' '92.0' '86.45' '3600']\n",
      " ['2017' 'Business' '95.4' '89.5' '3200']\n",
      " ['2017' 'Dentistry' '100.0' '100.0' '4050']\n",
      " ['2017' 'Education' '100.0' '100.0' '3600']\n",
      " ['2017' 'Engineering' '86.7' '79.5' '3500']\n",
      " ['2017' 'Health Sciences' '95.93' '89.4' '3333']\n",
      " ['2017' 'Information & Digital Technologies' '94.6' '90.1' '4000']\n",
      " ['2017' 'Sciences' '82.6' '65.3' '3250']\n",
      " ['2017' 'Law' '96.4' '92.8' '5000']\n",
      " ['2017' 'Medicine' '100.0' '100.0' '5000']\n",
      " ['2018' 'Arts` Humanities and the Social Sciences' '85.8' '54.73' '2733']\n",
      " ['2018' 'Architecture and Built Environment' '93.9' '89.15' '3700']\n",
      " ['2018' 'Business' '94.4' '89.1' '3400']\n",
      " ['2018' 'Dentistry' '100.0' '100.0' '4050']\n",
      " ['2018' 'Education' '100.0' '99.4' '3800']\n",
      " ['2018' 'Engineering' '89.9' '83.8' '3600']\n",
      " ['2018' 'Health Sciences' '94.73' '88.13' '3367']\n",
      " ['2018' 'Information & Digital Technologies' '95.0' '92.0' '4022']\n",
      " ['2018' 'Sciences' '84.4' '68.8' '3313']\n",
      " ['2018' 'Law' '95.3' '91.8' '5000']\n",
      " ['2018' 'Medicine' '99.87' '99.87' '5183']\n",
      " ['2019' 'Arts` Humanities and the Social Sciences' '85.97' '58.67'\n",
      "  '3400']\n",
      " ['2019' 'Architecture and Built Environment' '96.3' '91.65' '3800']\n",
      " ['2019' 'Business' '94.6' '88.8' '3500']\n",
      " ['2019' 'Dentistry' '100.0' '97.3' '4200']\n",
      " ['2019' 'Education' '100.0' '100.0' '3800']\n",
      " ['2019' 'Engineering' '88.4' '83.3' '3750']\n",
      " ['2019' 'Health Sciences' '97.43' '89.87' '3417']\n",
      " ['2019' 'Information & Digital Technologies' '95.4' '92.7' '4400']\n",
      " ['2019' 'Sciences' '86.9' '71.5' '3500']\n",
      " ['2019' 'Law' '97.0' '95.0' '5000']\n",
      " ['2019' 'Medicine' '99.6' '99.6' '5300']\n",
      " ['2020' 'Arts` Humanities and the Social Sciences' '84.53' '42.43'\n",
      "  '3358']\n",
      " ['2020' 'Architecture and Built Environment' '93.95' '81.75' '3750']\n",
      " ['2020' 'Business' '95.3' '76.0' '3500']\n",
      " ['2020' 'Dentistry' '100.0' '100.0' '4200']\n",
      " ['2020' 'Education' '100.0' '99.1' '3800']\n",
      " ['2020' 'Engineering' '93.6' '71.6' '3900']\n",
      " ['2020' 'Health Sciences' '97.13' '87.07' '3400']\n",
      " ['2020' 'Information & Digital Technologies' '94.8' '87.3' '4760']\n",
      " ['2020' 'Sciences' '91.6' '55.4' '3500']\n",
      " ['2020' 'Law' '93.4' '88.6' '5000']\n",
      " ['2020' 'Medicine' '100.0' '100.0' '5250']\n",
      " ['2021' 'Arts` Humanities and the Social Sciences' '88.73' '60.07'\n",
      "  '3383']\n",
      " ['2021' 'Architecture and Built Environment' '96.1' '92.75' '3800']\n",
      " ['2021' 'Business' '97.0' '88.7' '3723']\n",
      " ['2021' 'Dentistry' '100.0' '100.0' '4200']\n",
      " ['2021' 'Education' '100.0' '100.0' '3798']\n",
      " ['2021' 'Engineering' '94.0' '86.9' '3900']\n",
      " ['2021' 'Health Sciences' '94.17' '85.03' '3550']\n",
      " ['2021' 'Information & Digital Technologies' '97.8' '93.7' '5000']\n",
      " ['2021' 'Sciences' '91.7' '75.8' '3600']\n",
      " ['2021' 'Law' '97.9' '95.5' '5600']\n",
      " ['2021' 'Medicine' '99.87' '99.87' '5183']]\n"
     ]
    }
   ],
   "source": [
    "# format first and last columns as ints\n",
    "for i,a in enumerate(employ):\n",
    "    if i>0:\n",
    "        employ[i][0] = str(int(float(a[0])))\n",
    "        employ[i][4] = str(int(float(a[4])))\n",
    "print(employ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write back for one last time\n",
    "np.savetxt('datasets_cleaned/employment/employ.csv',employ,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for intake, we edit the column names to fit column names for Employment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Poly*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Initial Col Name   | New Col Name |\n",
    "|----------------------|------|\n",
    "| Engineering Sciences | Engineering |\n",
    "| Architecture, Building & Real Estate | Architecture and Built Environment|\n",
    "| Business & Administration | Business |\n",
    "| Information Technology | Information & Digital Technologies|\n",
    "| Applied Arts | Arts, Humanities and the Social Sciences|\n",
    "| Mass Communication | Arts, Humanities and the Social Sciences|\n",
    "| Services | Arts, Humanities and the Social Sciences|\n",
    "| Humanities & Social Sciences | Arts, Humanities and the Social Sciences|\n",
    "| Health Sciences | Health Sciences |\n",
    "| Education | Education |\n",
    "| Natural & Mathematical Sciences | Sciences |\n",
    "Natural, Physical & Mathematical Sciences | Sciences |\n",
    "| Law | Law |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyEdit = np.genfromtxt('datasets_cleaned/poly/poly_intake.csv',dtype='U64',delimiter=',',skip_header=1)\n",
    "for a in polyEdit:\n",
    "    if 'Engineering' in a[2]:\n",
    "        a[2] = 'Engineering'\n",
    "    elif 'Architecture' in a[2]:\n",
    "        a[2] = 'Architecture and Built Environment'\n",
    "    elif 'Business' in a[2]:\n",
    "        a[2] = 'Business'\n",
    "    elif 'Information Technology' in a[2]:\n",
    "        a[2] = 'Information & Digital Technologies'\n",
    "    elif a[2] == 'Applied Arts' or a[2] == 'Mass Communication' or a[2]=='Services' or 'Humanities' in a[2]:\n",
    "        a[2] = 'Arts` Humanities and the Social Sciences'\n",
    "    elif 'Sciences' in a[2] and a[2]!= 'Health Sciences':\n",
    "        a[2] = 'Sciences'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the dataset, the genders are either:\n",
    "- Both Male and Female or\n",
    "- Female Only\n",
    "\n",
    "To make it easier to compare between different genders, we can take the Both Male and Female row minus the Female Row for the same year and course\n",
    "\n",
    "From 2018 (inclusive) and before, the data is stored as follows:\n",
    "- MF, course1\n",
    "- F, course1\n",
    "- MF, course2\n",
    "- F, course2\n",
    "\n",
    "After 2018, \n",
    "- MF, course1\n",
    "- MF, course2\n",
    "- F, course1\n",
    "- F, course2\n",
    "\n",
    "As such we would need two seperate ways to do this. One for the years for 2018 and prior and another for after 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '70' '211' '89'] 12\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '228' '698' '259'] 13\n",
      "['2020' 'M' 'Information & Digital Technologies' '1883' '5824' '1808'] 14\n",
      "['2020' 'F' 'Information & Digital Technologies' '637' '2173' '802'] 15\n",
      "['2020' 'M' 'Law' '48' '118' '31'] 16\n",
      "['2020' 'F' 'Law' '60' '210' '62'] 17\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '134' '458' '159'] 18\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '415' '1334' '461'] 19\n",
      "['2020' 'M' 'Sciences' '440' '1090' '471'] 20\n",
      "['2020' 'F' 'Sciences' '669' '1947' '730'] 21\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '416' '1706' '526'] 22\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '375' '1222' '482'] 23\n"
     ]
    }
   ],
   "source": [
    "for i,a in enumerate(polyEdit):\n",
    "    # 2018 and before\n",
    "    if int(a[0])<=2018:\n",
    "        if a[1]=='MF':\n",
    "            a[1]='M'\n",
    "            a[3] = str(int(a[3])-int(polyEdit[i+1][3]))\n",
    "            a[4] = str(int(a[4])-int(polyEdit[i+1][4]))\n",
    "            a[5] = str(int(a[5])-int(polyEdit[i+1][5]))\n",
    "    # 2019 and 2020\n",
    "    else:\n",
    "        if a[1]=='MF':\n",
    "            a[1]='M'\n",
    "            # Since there are 12 different courses\n",
    "            a[3] = str(int(a[3])-int(polyEdit[i+12][3]))\n",
    "            a[4] = str(int(a[4])-int(polyEdit[i+12][4]))\n",
    "            a[5] = str(int(a[5])-int(polyEdit[i+12][5]))\n",
    "\n",
    "\n",
    "# Reformat data for 2019 and 2020 (to make it similar to 2018 and before)\n",
    "counter = 0\n",
    "for i in range(len(polyEdit)):\n",
    "    if int(polyEdit[i][0])==2019:\n",
    "        if counter<12:\n",
    "            # We have to use vstack instead of concat or append since we are adding a 1d array to a 2d array (and since axis=0)\n",
    "            polyEdit = np.vstack((polyEdit[:i+1+counter],polyEdit[i+12+counter],polyEdit[i+1+counter:]))\n",
    "        # remove duplicates from 2019\n",
    "        elif counter==24:\n",
    "            polyEdit = np.delete(polyEdit,np.s_[i:i+12],0)\n",
    "        counter+=1\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(polyEdit)):\n",
    "    if int(polyEdit[i][0])==2020:\n",
    "        if counter<12:\n",
    "            polyEdit = np.vstack((polyEdit[:i+1+counter],polyEdit[i+12+counter],polyEdit[i+1+counter:]))\n",
    "        else:\n",
    "            print(polyEdit[i],counter)\n",
    "        counter+=1\n",
    "\n",
    "# since the last 12 rows are duplicates, we remove them\n",
    "polyEdit = np.delete(polyEdit,np.s_[-12:],0)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '441' '1055' '248']\n",
      "['2005' 'F' 'Arts` Humanities and the Social Sciences' '687' '1538' '302']\n",
      "['2005' 'M' 'Architecture and Built Environment' '203' '596' '176']\n",
      "['2005' 'F' 'Architecture and Built Environment' '312' '870' '249']\n",
      "['2005' 'M' 'Business' '1094' '3105' '774']\n",
      "['2005' 'F' 'Business' '2389' '7038' '2270']\n",
      "['2005' 'M' 'Education' '9' '15' '0']\n",
      "['2005' 'F' 'Education' '180' '469' '111']\n",
      "['2005' 'M' 'Engineering' '5729' '16523' '4531']\n",
      "['2005' 'F' 'Engineering' '2097' '5939' '2005']\n",
      "['2005' 'M' 'Health Sciences' '313' '991' '139']\n",
      "['2005' 'F' 'Health Sciences' '1326' '3971' '877']\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '10' '10' '0']\n",
      "['2005' 'F' 'Arts` Humanities and the Social Sciences' '71' '73' '0']\n",
      "['2005' 'M' 'Information & Digital Technologies' '2235' '6542' '1892']\n",
      "['2005' 'F' 'Information & Digital Technologies' '1887' '5065' '1464']\n",
      "['2005' 'M' 'Law' '43' '120' '31']\n",
      "['2005' 'F' 'Law' '83' '221' '71']\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '124' '397' '137']\n",
      "['2005' 'F' 'Arts` Humanities and the Social Sciences' '324' '1029' '282']\n",
      "['2005' 'M' 'Sciences' '497' '1166' '321']\n",
      "['2005' 'F' 'Sciences' '712' '1678' '447']\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '72' '296' '153']\n",
      "['2005' 'F' 'Arts` Humanities and the Social Sciences' '68' '173' '35']\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '558' '1361' '223']\n",
      "['2006' 'F' 'Arts` Humanities and the Social Sciences' '742' '1894' '319']\n",
      "['2006' 'M' 'Architecture and Built Environment' '254' '667' '161']\n",
      "['2006' 'F' 'Architecture and Built Environment' '342' '955' '233']\n",
      "['2006' 'M' 'Business' '1457' '3644' '838']\n",
      "['2006' 'F' 'Business' '2487' '7225' '2208']\n",
      "['2006' 'M' 'Education' '57' '69' '3']\n",
      "['2006' 'F' 'Education' '209' '545' '128']\n",
      "['2006' 'M' 'Engineering' '6101' '17516' '4629']\n",
      "['2006' 'F' 'Engineering' '2108' '6197' '1786']\n",
      "['2006' 'M' 'Health Sciences' '401' '1179' '248']\n",
      "['2006' 'F' 'Health Sciences' '1554' '4428' '1080']\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '9' '17' '0']\n",
      "['2006' 'F' 'Arts` Humanities and the Social Sciences' '66' '136' '0']\n",
      "['2006' 'M' 'Information & Digital Technologies' '2244' '6619' '1874']\n",
      "['2006' 'F' 'Information & Digital Technologies' '1728' '5134' '1477']\n",
      "['2006' 'M' 'Law' '46' '132' '25']\n",
      "['2006' 'F' 'Law' '70' '221' '63']\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '140' '409' '120']\n",
      "['2006' 'F' 'Arts` Humanities and the Social Sciences' '310' '1019' '296']\n",
      "['2006' 'M' 'Sciences' '500' '1286' '301']\n",
      "['2006' 'F' 'Sciences' '684' '1777' '460']\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '115' '321' '116']\n",
      "['2006' 'F' 'Arts` Humanities and the Social Sciences' '94' '211' '50']\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '590' '1580' '298']\n",
      "['2007' 'F' 'Arts` Humanities and the Social Sciences' '865' '2221' '409']\n",
      "['2007' 'M' 'Architecture and Built Environment' '261' '732' '176']\n",
      "['2007' 'F' 'Architecture and Built Environment' '363' '1010' '273']\n",
      "['2007' 'M' 'Business' '1649' '4259' '996']\n",
      "['2007' 'F' 'Business' '2909' '7839' '2247']\n",
      "['2007' 'M' 'Education' '71' '142' '3']\n",
      "['2007' 'F' 'Education' '238' '623' '156']\n",
      "['2007' 'M' 'Engineering' '5918' '18255' '4622']\n",
      "['2007' 'F' 'Engineering' '2054' '6461' '1685']\n",
      "['2007' 'M' 'Health Sciences' '457' '1263' '355']\n",
      "['2007' 'F' 'Health Sciences' '1653' '4602' '1400']\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '23' '40' '0']\n",
      "['2007' 'F' 'Arts` Humanities and the Social Sciences' '88' '222' '0']\n",
      "['2007' 'M' 'Information & Digital Technologies' '2318' '6889' '1840']\n",
      "['2007' 'F' 'Information & Digital Technologies' '1651' '5199' '1410']\n",
      "['2007' 'M' 'Law' '36' '125' '38']\n",
      "['2007' 'F' 'Law' '81' '226' '65']\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '176' '439' '135']\n",
      "['2007' 'F' 'Arts` Humanities and the Social Sciences' '354' '989' '377']\n",
      "['2007' 'M' 'Sciences' '521' '1452' '311']\n",
      "['2007' 'F' 'Sciences' '846' '2095' '453']\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '154' '380' '113']\n",
      "['2007' 'F' 'Arts` Humanities and the Social Sciences' '86' '247' '51']\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '728' '1821' '381']\n",
      "['2008' 'F' 'Arts` Humanities and the Social Sciences' '918' '2355' '582']\n",
      "['2008' 'M' 'Architecture and Built Environment' '296' '792' '173']\n",
      "['2008' 'F' 'Architecture and Built Environment' '327' '982' '292']\n",
      "['2008' 'M' 'Business' '2303' '5591' '1061']\n",
      "['2008' 'F' 'Business' '3524' '9221' '2315']\n",
      "['2008' 'M' 'Education' '6' '18' '9']\n",
      "['2008' 'F' 'Education' '188' '529' '175']\n",
      "['2008' 'M' 'Engineering' '5643' '18117' '5161']\n",
      "['2008' 'F' 'Engineering' '1809' '6039' '1996']\n",
      "['2008' 'M' 'Health Sciences' '575' '1421' '348']\n",
      "['2008' 'F' 'Health Sciences' '1788' '5002' '1327']\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '173' '350' '8']\n",
      "['2008' 'F' 'Arts` Humanities and the Social Sciences' '306' '603' '67']\n",
      "['2008' 'M' 'Information & Digital Technologies' '2236' '6930' '2014']\n",
      "['2008' 'F' 'Information & Digital Technologies' '1707' '5057' '1716']\n",
      "['2008' 'M' 'Law' '62' '130' '43']\n",
      "['2008' 'F' 'Law' '66' '204' '78']\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '164' '503' '117']\n",
      "['2008' 'F' 'Arts` Humanities and the Social Sciences' '378' '1036' '318']\n",
      "['2008' 'M' 'Sciences' '521' '1504' '410']\n",
      "['2008' 'F' 'Sciences' '833' '2207' '568']\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '178' '431' '96']\n",
      "['2008' 'F' 'Arts` Humanities and the Social Sciences' '109' '294' '62']\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '748' '2052' '428']\n",
      "['2009' 'F' 'Arts` Humanities and the Social Sciences' '942' '2629' '576']\n",
      "['2009' 'M' 'Architecture and Built Environment' '254' '788' '233']\n",
      "['2009' 'F' 'Architecture and Built Environment' '291' '936' '307']\n",
      "['2009' 'M' 'Business' '2191' '6077' '1409']\n",
      "['2009' 'F' 'Business' '3524' '9947' '2533']\n",
      "['2009' 'M' 'Education' '16' '29' '4']\n",
      "['2009' 'F' 'Education' '190' '540' '173']\n",
      "['2009' 'M' 'Engineering' '5884' '18326' '5427']\n",
      "['2009' 'F' 'Engineering' '1891' '5922' '1972']\n",
      "['2009' 'M' 'Health Sciences' '586' '1605' '363']\n",
      "['2009' 'F' 'Health Sciences' '1953' '5477' '1396']\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '214' '491' '57']\n",
      "['2009' 'F' 'Arts` Humanities and the Social Sciences' '321' '803' '96']\n",
      "['2009' 'M' 'Information & Digital Technologies' '2237' '6905' '1967']\n",
      "['2009' 'F' 'Information & Digital Technologies' '1789' '5192' '1505']\n",
      "['2009' 'M' 'Law' '47' '132' '41']\n",
      "['2009' 'F' 'Law' '82' '222' '55']\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '214' '557' '132']\n",
      "['2009' 'F' 'Arts` Humanities and the Social Sciences' '471' '1186' '303']\n",
      "['2009' 'M' 'Sciences' '586' '1561' '452']\n",
      "['2009' 'F' 'Sciences' '917' '2416' '592']\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '149' '443' '121']\n",
      "['2009' 'F' 'Arts` Humanities and the Social Sciences' '127' '330' '82']\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '865' '2297' '490']\n",
      "['2010' 'F' 'Arts` Humanities and the Social Sciences' '1074' '2872' '703']\n",
      "['2010' 'M' 'Architecture and Built Environment' '273' '811' '221']\n",
      "['2010' 'F' 'Architecture and Built Environment' '330' '923' '318']\n",
      "['2010' 'M' 'Business' '2140' '6512' '1582']\n",
      "['2010' 'F' 'Business' '3567' '10455' '2934']\n",
      "['2010' 'M' 'Education' '13' '35' '7']\n",
      "['2010' 'F' 'Education' '258' '625' '167']\n",
      "['2010' 'M' 'Engineering' '5803' '18216' '5402']\n",
      "['2010' 'F' 'Engineering' '1752' '5666' '1893']\n",
      "['2010' 'M' 'Health Sciences' '633' '1809' '377']\n",
      "['2010' 'F' 'Health Sciences' '2022' '5779' '1591']\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '291' '680' '92']\n",
      "['2010' 'F' 'Arts` Humanities and the Social Sciences' '392' '993' '183']\n",
      "['2010' 'M' 'Information & Digital Technologies' '2101' '6768' '2107']\n",
      "['2010' 'F' 'Information & Digital Technologies' '1586' '5117' '1586']\n",
      "['2010' 'M' 'Law' '58' '152' '34']\n",
      "['2010' 'F' 'Law' '85' '225' '74']\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '179' '593' '123']\n",
      "['2010' 'F' 'Arts` Humanities and the Social Sciences' '485' '1347' '254']\n",
      "['2010' 'M' 'Sciences' '541' '1660' '407']\n",
      "['2010' 'F' 'Sciences' '993' '2686' '663']\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '148' '428' '141']\n",
      "['2010' 'F' 'Arts` Humanities and the Social Sciences' '118' '340' '96']\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '860' '2503' '573']\n",
      "['2011' 'F' 'Arts` Humanities and the Social Sciences' '1130' '3104' '770']\n",
      "['2011' 'M' 'Architecture and Built Environment' '316' '817' '268']\n",
      "['2011' 'F' 'Architecture and Built Environment' '459' '1063' '297']\n",
      "['2011' 'M' 'Business' '2279' '6644' '2035']\n",
      "['2011' 'F' 'Business' '3510' '10571' '3271']\n",
      "['2011' 'M' 'Education' '21' '49' '5']\n",
      "['2011' 'F' 'Education' '255' '687' '178']\n",
      "['2011' 'M' 'Engineering' '6109' '18323' '5372']\n",
      "['2011' 'F' 'Engineering' '1837' '5550' '1814']\n",
      "['2011' 'M' 'Health Sciences' '631' '1868' '497']\n",
      "['2011' 'F' 'Health Sciences' '1906' '5879' '1661']\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '348' '843' '151']\n",
      "['2011' 'F' 'Arts` Humanities and the Social Sciences' '422' '1109' '278']\n",
      "['2011' 'M' 'Information & Digital Technologies' '2316' '6750' '2125']\n",
      "['2011' 'F' 'Information & Digital Technologies' '1626' '4939' '1607']\n",
      "['2011' 'M' 'Law' '64' '169' '42']\n",
      "['2011' 'F' 'Law' '77' '235' '53']\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '169' '523' '163']\n",
      "['2011' 'F' 'Arts` Humanities and the Social Sciences' '418' '1283' '348']\n",
      "['2011' 'M' 'Sciences' '603' '1774' '446']\n",
      "['2011' 'F' 'Sciences' '984' '2846' '732']\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '220' '502' '135']\n",
      "['2011' 'F' 'Arts` Humanities and the Social Sciences' '177' '412' '97']\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '860' '2637' '704']\n",
      "['2012' 'F' 'Arts` Humanities and the Social Sciences' '1164' '3346' '855']\n",
      "['2012' 'M' 'Architecture and Built Environment' '356' '903' '241']\n",
      "['2012' 'F' 'Architecture and Built Environment' '423' '1185' '271']\n",
      "['2012' 'M' 'Business' '2294' '6743' '2061']\n",
      "['2012' 'F' 'Business' '3772' '10706' '3361']\n",
      "['2012' 'M' 'Education' '19' '53' '16']\n",
      "['2012' 'F' 'Education' '275' '768' '180']\n",
      "['2012' 'M' 'Engineering' '5988' '18236' '5476']\n",
      "['2012' 'F' 'Engineering' '1753' '5301' '1815']\n",
      "['2012' 'M' 'Health Sciences' '568' '1823' '555']\n",
      "['2012' 'F' 'Health Sciences' '1675' '5515' '1923']\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '340' '966' '188']\n",
      "['2012' 'F' 'Arts` Humanities and the Social Sciences' '461' '1248' '289']\n",
      "['2012' 'M' 'Information & Digital Technologies' '2417' '6880' '2062']\n",
      "['2012' 'F' 'Information & Digital Technologies' '1559' '4797' '1580']\n",
      "['2012' 'M' 'Law' '60' '182' '39']\n",
      "['2012' 'F' 'Law' '79' '232' '75']\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '169' '513' '201']\n",
      "['2012' 'F' 'Arts` Humanities and the Social Sciences' '459' '1182' '452']\n",
      "['2012' 'M' 'Sciences' '589' '1764' '546']\n",
      "['2012' 'F' 'Sciences' '1050' '2971' '845']\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '217' '553' '146']\n",
      "['2012' 'F' 'Arts` Humanities and the Social Sciences' '207' '499' '118']\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '883' '2546' '783']\n",
      "['2013' 'F' 'Arts` Humanities and the Social Sciences' '1214' '3389' '963']\n",
      "['2013' 'M' 'Architecture and Built Environment' '349' '986' '277']\n",
      "['2013' 'F' 'Architecture and Built Environment' '447' '1310' '353']\n",
      "['2013' 'M' 'Business' '2406' '7030' '2035']\n",
      "['2013' 'F' 'Business' '3861' '11087' '3365']\n",
      "['2013' 'M' 'Education' '35' '75' '12']\n",
      "['2013' 'F' 'Education' '288' '805' '250']\n",
      "['2013' 'M' 'Engineering' '5964' '18269' '5398']\n",
      "['2013' 'F' 'Engineering' '1691' '5205' '1618']\n",
      "['2013' 'M' 'Health Sciences' '568' '1749' '601']\n",
      "['2013' 'F' 'Health Sciences' '1842' '5413' '1853']\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '331' '1012' '258']\n",
      "['2013' 'F' 'Arts` Humanities and the Social Sciences' '425' '1278' '369']\n",
      "['2013' 'M' 'Information & Digital Technologies' '2325' '7102' '2014']\n",
      "['2013' 'F' 'Information & Digital Technologies' '1431' '4520' '1509']\n",
      "['2013' 'M' 'Law' '64' '187' '54']\n",
      "['2013' 'F' 'Law' '76' '218' '78']\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '188' '522' '175']\n",
      "['2013' 'F' 'Arts` Humanities and the Social Sciences' '473' '1328' '463']\n",
      "['2013' 'M' 'Sciences' '610' '1785' '547']\n",
      "['2013' 'F' 'Sciences' '992' '2980' '922']\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '214' '588' '143']\n",
      "['2013' 'F' 'Arts` Humanities and the Social Sciences' '202' '586' '117']\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '940' '2685' '725']\n",
      "['2014' 'F' 'Arts` Humanities and the Social Sciences' '1183' '3448' '995']\n",
      "['2014' 'M' 'Architecture and Built Environment' '326' '1010' '272']\n",
      "['2014' 'F' 'Architecture and Built Environment' '471' '1329' '435']\n",
      "['2014' 'M' 'Business' '2218' '6984' '2202']\n",
      "['2014' 'F' 'Business' '3799' '11355' '3394']\n",
      "['2014' 'M' 'Education' '16' '66' '21']\n",
      "['2014' 'F' 'Education' '317' '872' '239']\n",
      "['2014' 'M' 'Engineering' '5472' '17185' '5371']\n",
      "['2014' 'F' 'Engineering' '1558' '4734' '1612']\n",
      "['2014' 'M' 'Health Sciences' '617' '1748' '575']\n",
      "['2014' 'F' 'Health Sciences' '1659' '5154' '1838']\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '348' '1027' '315']\n",
      "['2014' 'F' 'Arts` Humanities and the Social Sciences' '430' '1299' '388']\n",
      "['2014' 'M' 'Information & Digital Technologies' '2067' '6942' '2094']\n",
      "['2014' 'F' 'Information & Digital Technologies' '1230' '4204' '1483']\n",
      "['2014' 'M' 'Law' '55' '183' '56']\n",
      "['2014' 'F' 'Law' '79' '224' '66']\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '163' '519' '162']\n",
      "['2014' 'F' 'Arts` Humanities and the Social Sciences' '491' '1413' '393']\n",
      "['2014' 'M' 'Sciences' '607' '1804' '555']\n",
      "['2014' 'F' 'Sciences' '1022' '3010' '931']\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '411' '1225' '361']\n",
      "['2014' 'F' 'Arts` Humanities and the Social Sciences' '298' '894' '238']\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '718' '2287' '731']\n",
      "['2015' 'F' 'Arts` Humanities and the Social Sciences' '1021' '3186' '977']\n",
      "['2015' 'M' 'Architecture and Built Environment' '280' '934' '319']\n",
      "['2015' 'F' 'Architecture and Built Environment' '390' '1283' '396']\n",
      "['2015' 'M' 'Business' '1809' '6231' '2071']\n",
      "['2015' 'F' 'Business' '3062' '10062' '3384']\n",
      "['2015' 'M' 'Education' '21' '66' '18']\n",
      "['2015' 'F' 'Education' '319' '911' '274']\n",
      "['2015' 'M' 'Engineering' '5612' '17117' '5308']\n",
      "['2015' 'F' 'Engineering' '1705' '5064' '1659']\n",
      "['2015' 'M' 'Health Sciences' '694' '2166' '604']\n",
      "['2015' 'F' 'Health Sciences' '1996' '5794' '1693']\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '82' '274' '86']\n",
      "['2015' 'F' 'Arts` Humanities and the Social Sciences' '248' '773' '257']\n",
      "['2015' 'M' 'Information & Digital Technologies' '1963' '6394' '2115']\n",
      "['2015' 'F' 'Information & Digital Technologies' '1074' '3629' '1298']\n",
      "['2015' 'M' 'Law' '43' '168' '55']\n",
      "['2015' 'F' 'Law' '73' '222' '71']\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '153' '537' '174']\n",
      "['2015' 'F' 'Arts` Humanities and the Social Sciences' '456' '1496' '470']\n",
      "['2015' 'M' 'Sciences' '551' '1747' '558']\n",
      "['2015' 'F' 'Sciences' '864' '2817' '919']\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '550' '1959' '611']\n",
      "['2015' 'F' 'Arts` Humanities and the Social Sciences' '567' '1748' '583']\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '710' '2172' '759']\n",
      "['2016' 'F' 'Arts` Humanities and the Social Sciences' '1011' '3064'\n",
      " '1024']\n",
      "['2016' 'M' 'Architecture and Built Environment' '252' '832' '323']\n",
      "['2016' 'F' 'Architecture and Built Environment' '371' '1207' '420']\n",
      "['2016' 'M' 'Business' '1800' '5797' '2178']\n",
      "['2016' 'F' 'Business' '2846' '9406' '3417']\n",
      "['2016' 'M' 'Education' '38' '71' '30']\n",
      "['2016' 'F' 'Education' '548' '1181' '277']\n",
      "['2016' 'M' 'Engineering' '5416' '16613' '5338']\n",
      "['2016' 'F' 'Engineering' '1395' '4721' '1601']\n",
      "['2016' 'M' 'Health Sciences' '643' '2102' '661']\n",
      "['2016' 'F' 'Health Sciences' '1894' '5704' '1895']\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '86' '262' '92']\n",
      "['2016' 'F' 'Arts` Humanities and the Social Sciences' '256' '758' '261']\n",
      "['2016' 'M' 'Information & Digital Technologies' '1863' '6023' '2030']\n",
      "['2016' 'F' 'Information & Digital Technologies' '906' '3175' '1275']\n",
      "['2016' 'M' 'Law' '35' '139' '58']\n",
      "['2016' 'F' 'Law' '66' '218' '68']\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '161' '484' '203']\n",
      "['2016' 'F' 'Arts` Humanities and the Social Sciences' '457' '1436' '498']\n",
      "['2016' 'M' 'Sciences' '507' '1668' '553']\n",
      "['2016' 'F' 'Sciences' '789' '2634' '904']\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '592' '1858' '668']\n",
      "['2016' 'F' 'Arts` Humanities and the Social Sciences' '479' '1624' '571']\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '738' '2163' '682']\n",
      "['2017' 'F' 'Arts` Humanities and the Social Sciences' '1147' '3128'\n",
      " '1000']\n",
      "['2017' 'M' 'Architecture and Built Environment' '324' '850' '295']\n",
      "['2017' 'F' 'Architecture and Built Environment' '390' '1129' '441']\n",
      "['2017' 'M' 'Business' '1903' '5617' '2032']\n",
      "['2017' 'F' 'Business' '2931' '8836' '3384']\n",
      "['2017' 'M' 'Education' '59' '115' '13']\n",
      "['2017' 'F' 'Education' '650' '1503' '307']\n",
      "['2017' 'M' 'Engineering' '5457' '16501' '5043']\n",
      "['2017' 'F' 'Engineering' '1481' '4518' '1572']\n",
      "['2017' 'M' 'Health Sciences' '634' '1991' '696']\n",
      "['2017' 'F' 'Health Sciences' '1933' '5807' '1771']\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '93' '256' '90']\n",
      "['2017' 'F' 'Arts` Humanities and the Social Sciences' '298' '792' '257']\n",
      "['2017' 'M' 'Information & Digital Technologies' '2020' '5877' '1990']\n",
      "['2017' 'F' 'Information & Digital Technologies' '889' '2889' '1099']\n",
      "['2017' 'M' 'Law' '33' '122' '48']\n",
      "['2017' 'F' 'Law' '64' '208' '72']\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '167' '474' '174']\n",
      "['2017' 'F' 'Arts` Humanities and the Social Sciences' '475' '1368' '523']\n",
      "['2017' 'M' 'Sciences' '526' '1582' '574']\n",
      "['2017' 'F' 'Sciences' '778' '2400' '955']\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '574' '1751' '645']\n",
      "['2017' 'F' 'Arts` Humanities and the Social Sciences' '500' '1559' '547']\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '783' '2209' '669']\n",
      "['2018' 'F' 'Arts` Humanities and the Social Sciences' '1111' '3215' '941']\n",
      "['2018' 'M' 'Architecture and Built Environment' '342' '903' '244']\n",
      "['2018' 'F' 'Architecture and Built Environment' '382' '1104' '370']\n",
      "['2018' 'M' 'Business' '1831' '5618' '1778']\n",
      "['2018' 'F' 'Business' '2811' '8546' '3006']\n",
      "['2018' 'M' 'Education' '57' '146' '20']\n",
      "['2018' 'F' 'Education' '660' '1843' '312']\n",
      "['2018' 'M' 'Engineering' '5395' '16317' '4997']\n",
      "['2018' 'F' 'Engineering' '1473' '4328' '1543']\n",
      "['2018' 'M' 'Health Sciences' '665' '1947' '670']\n",
      "['2018' 'F' 'Health Sciences' '2093' '5909' '1895']\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '84' '262' '77']\n",
      "['2018' 'F' 'Arts` Humanities and the Social Sciences' '268' '809' '233']\n",
      "['2018' 'M' 'Information & Digital Technologies' '2003' '5930' '1751']\n",
      "['2018' 'F' 'Information & Digital Technologies' '817' '2608' '996']\n",
      "['2018' 'M' 'Law' '34' '104' '48']\n",
      "['2018' 'F' 'Law' '70' '197' '76']\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '175' '497' '145']\n",
      "['2018' 'F' 'Arts` Humanities and the Social Sciences' '500' '1420' '437']\n",
      "['2018' 'M' 'Sciences' '459' '1486' '528']\n",
      "['2018' 'F' 'Sciences' '773' '2308' '825']\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '647' '1843' '512']\n",
      "['2018' 'F' 'Arts` Humanities and the Social Sciences' '436' '1436' '541']\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '692' '2199' '646']\n",
      "['2019' 'F' 'Arts` Humanities and the Social Sciences' '1084' '3290' '934']\n",
      "['2019' 'M' 'Architecture and Built Environment' '308' '939' '242']\n",
      "['2019' 'F' 'Architecture and Built Environment' '326' '1052' '337']\n",
      "['2019' 'M' 'Business' '1629' '5432' '1756']\n",
      "['2019' 'F' 'Business' '2659' '8359' '2733']\n",
      "['2019' 'M' 'Education' '57' '165' '33']\n",
      "['2019' 'F' 'Education' '660' '1951' '522']\n",
      "['2019' 'M' 'Engineering' '4953' '15852' '4790']\n",
      "['2019' 'F' 'Engineering' '1409' '4316' '1271']\n",
      "['2019' 'M' 'Health Sciences' '691' '1988' '596']\n",
      "['2019' 'F' 'Health Sciences' '1901' '5904' '1834']\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '66' '242' '83']\n",
      "['2019' 'F' 'Arts` Humanities and the Social Sciences' '258' '816' '242']\n",
      "['2019' 'M' 'Information & Digital Technologies' '1921' '5927' '1705']\n",
      "['2019' 'F' 'Information & Digital Technologies' '730' '2412' '843']\n",
      "['2019' 'M' 'Law' '36' '104' '35']\n",
      "['2019' 'F' 'Law' '69' '200' '61']\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '153' '490' '154']\n",
      "['2019' 'F' 'Arts` Humanities and the Social Sciences' '437' '1396' '447']\n",
      "['2019' 'M' 'Sciences' '445' '1423' '475']\n",
      "['2019' 'F' 'Sciences' '691' '2200' '743']\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '521' '1764' '581']\n",
      "['2019' 'F' 'Arts` Humanities and the Social Sciences' '375' '1312' '469']\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '662' '2113' '670']\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '1049' '3199'\n",
      " '1059']\n",
      "['2020' 'M' 'Architecture and Built Environment' '295' '904' '283']\n",
      "['2020' 'F' 'Architecture and Built Environment' '329' '988' '350']\n",
      "['2020' 'M' 'Business' '1635' '5149' '1818']\n",
      "['2020' 'F' 'Business' '2521' '7975' '2785']\n",
      "['2020' 'M' 'Education' '50' '163' '52']\n",
      "['2020' 'F' 'Education' '663' '2001' '661']\n",
      "['2020' 'M' 'Engineering' '4695' '15311' '4964']\n",
      "['2020' 'F' 'Engineering' '1224' '4220' '1363']\n",
      "['2020' 'M' 'Health Sciences' '674' '2031' '586']\n",
      "['2020' 'F' 'Health Sciences' '1842' '5888' '1789']\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '70' '211' '89']\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '228' '698' '259']\n",
      "['2020' 'M' 'Information & Digital Technologies' '1883' '5824' '1808']\n",
      "['2020' 'F' 'Information & Digital Technologies' '637' '2173' '802']\n",
      "['2020' 'M' 'Law' '48' '118' '31']\n",
      "['2020' 'F' 'Law' '60' '210' '62']\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '134' '458' '159']\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '415' '1334' '461']\n",
      "['2020' 'M' 'Sciences' '440' '1090' '471']\n",
      "['2020' 'F' 'Sciences' '669' '1947' '730']\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '416' '1706' '526']\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '375' '1222' '482']\n"
     ]
    }
   ],
   "source": [
    "for a in polyEdit:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    }
   ],
   "source": [
    "# Number of rows (+1 for header) we should get\n",
    "# The reason for -2 is because poly has no 'Medicine' and 'Dentistry'\n",
    "print((len(unique_courses)-2)*2*(2021-2005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arts` Humanities and the Social Sciences [0, 12, 18, 22]\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '10' '10' '0'] 1\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '124' '397' '137'] 2\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '72' '296' '153'] 3\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '647' '1758' '538']\n",
      "['2005' 'F' 'Arts` Humanities and the Social Sciences' '1150' '2813' '619']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [24, 36, 42, 46]\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '9' '17' '0'] 1\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '140' '409' '120'] 2\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '115' '321' '116'] 3\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '822' '2108' '459']\n",
      "['2006' 'F' 'Arts` Humanities and the Social Sciences' '1212' '3260' '665']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [48, 60, 66, 70]\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '23' '40' '0'] 1\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '176' '439' '135'] 2\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '154' '380' '113'] 3\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '943' '2439' '546']\n",
      "['2007' 'F' 'Arts` Humanities and the Social Sciences' '1393' '3679' '837']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [72, 84, 90, 94]\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '173' '350' '8'] 1\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '164' '503' '117'] 2\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '178' '431' '96'] 3\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '1243' '3105' '602']\n",
      "['2008' 'F' 'Arts` Humanities and the Social Sciences' '1711' '4288'\n",
      " '1029']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [96, 108, 114, 118]\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '214' '491' '57'] 1\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '214' '557' '132'] 2\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '149' '443' '121'] 3\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '1325' '3543' '738']\n",
      "['2009' 'F' 'Arts` Humanities and the Social Sciences' '1861' '4948'\n",
      " '1057']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [120, 132, 138, 142]\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '291' '680' '92'] 1\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '179' '593' '123'] 2\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '148' '428' '141'] 3\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '1483' '3998' '846']\n",
      "['2010' 'F' 'Arts` Humanities and the Social Sciences' '2069' '5552'\n",
      " '1236']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [144, 156, 162, 166]\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '348' '843' '151'] 1\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '169' '523' '163'] 2\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '220' '502' '135'] 3\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '1597' '4371'\n",
      " '1022']\n",
      "['2011' 'F' 'Arts` Humanities and the Social Sciences' '2147' '5908'\n",
      " '1493']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [168, 180, 186, 190]\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '340' '966' '188'] 1\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '169' '513' '201'] 2\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '217' '553' '146'] 3\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '1586' '4669'\n",
      " '1239']\n",
      "['2012' 'F' 'Arts` Humanities and the Social Sciences' '2291' '6275'\n",
      " '1714']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [192, 204, 210, 214]\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '331' '1012' '258'] 1\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '188' '522' '175'] 2\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '214' '588' '143'] 3\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '1616' '4668'\n",
      " '1359']\n",
      "['2013' 'F' 'Arts` Humanities and the Social Sciences' '2314' '6581'\n",
      " '1912']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [216, 228, 234, 238]\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '348' '1027' '315'] 1\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '163' '519' '162'] 2\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '411' '1225' '361'] 3\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '1862' '5456'\n",
      " '1563']\n",
      "['2014' 'F' 'Arts` Humanities and the Social Sciences' '2402' '7054'\n",
      " '2014']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [240, 252, 258, 262]\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '82' '274' '86'] 1\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '153' '537' '174'] 2\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '550' '1959' '611'] 3\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '1503' '5057'\n",
      " '1602']\n",
      "['2015' 'F' 'Arts` Humanities and the Social Sciences' '2292' '7203'\n",
      " '2287']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [264, 276, 282, 286]\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '86' '262' '92'] 1\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '161' '484' '203'] 2\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '592' '1858' '668'] 3\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '1549' '4776'\n",
      " '1722']\n",
      "['2016' 'F' 'Arts` Humanities and the Social Sciences' '2203' '6882'\n",
      " '2354']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [288, 300, 306, 310]\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '93' '256' '90'] 1\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '167' '474' '174'] 2\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '574' '1751' '645'] 3\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '1572' '4644'\n",
      " '1591']\n",
      "['2017' 'F' 'Arts` Humanities and the Social Sciences' '2420' '6847'\n",
      " '2327']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [312, 324, 330, 334]\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '84' '262' '77'] 1\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '175' '497' '145'] 2\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '647' '1843' '512'] 3\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '1689' '4811'\n",
      " '1403']\n",
      "['2018' 'F' 'Arts` Humanities and the Social Sciences' '2315' '6880'\n",
      " '2152']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [336, 348, 354, 358]\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '66' '242' '83'] 1\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '153' '490' '154'] 2\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '521' '1764' '581'] 3\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '1432' '4695'\n",
      " '1464']\n",
      "['2019' 'F' 'Arts` Humanities and the Social Sciences' '2154' '6814'\n",
      " '2092']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [360, 372, 378, 382]\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '70' '211' '89'] 1\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '134' '458' '159'] 2\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '416' '1706' '526'] 3\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '1282' '4488'\n",
      " '1444']\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '2067' '6453'\n",
      " '2261']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n"
     ]
    }
   ],
   "source": [
    "# Add the data to the dictionary\n",
    "for year in range(2005,2021):\n",
    "    \n",
    "    # Create a dictionary to store the data\n",
    "    course_dict = {}\n",
    "    for course in unique_courses:\n",
    "        course_dict[course] = []\n",
    "\n",
    "    for i,a in enumerate(polyEdit):\n",
    "        if a[2] in course_dict and float(a[0])==year:\n",
    "            if a[1]=='M':\n",
    "                course_dict[a[2]].append(i)\n",
    "\n",
    "\n",
    "    for k,v in course_dict.items():\n",
    "        if len(v)>1:\n",
    "            print(k,v)\n",
    "            for j,n in enumerate(v):\n",
    "                # Combine the data into one numpy array\n",
    "                if j>0:\n",
    "                    print(polyEdit[n],j)\n",
    "\n",
    "                    # For males\n",
    "                    polyEdit[v[0]][3] = str(int(polyEdit[v[0]][3])+int(polyEdit[n][3]))\n",
    "                    polyEdit[v[0]][4] = str(int(polyEdit[v[0]][4])+int(polyEdit[n][4]))\n",
    "                    polyEdit[v[0]][5] = str(int(polyEdit[v[0]][5])+int(polyEdit[n][5]))\n",
    "\n",
    "                    # Repeat for Females\n",
    "                    polyEdit[v[0]+1][3] = str(int(polyEdit[v[0]+1][3])+int(polyEdit[n+1][3]))\n",
    "                    polyEdit[v[0]+1][4] = str(int(polyEdit[v[0]+1][4])+int(polyEdit[n+1][4]))\n",
    "                    polyEdit[v[0]+1][5] = str(int(polyEdit[v[0]+1][5])+int(polyEdit[n+1][5]))\n",
    "\n",
    "\n",
    "                    # Remove the duplicates later\n",
    "                    polyEdit[n] = np.array(['NA','NA','NA','NA','NA','NA'])\n",
    "                    polyEdit[n+1] = np.array(['NA','NA','NA','NA','NA','NA'])\n",
    "            \n",
    "            # No need to get average since these are enrollment, intake and grad numbers (not percentages like before)\n",
    "\n",
    "            \n",
    "            for n in v:\n",
    "                print(polyEdit[n])\n",
    "                print(polyEdit[n+1])\n",
    "    year+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['year' 'sex' 'course' 'intake' 'enrolment' 'graduates']\n",
      " ['2005' 'M' 'Arts` Humanities and the Social Sciences' '647' '1758'\n",
      "  '538']\n",
      " ['2005' 'F' 'Arts` Humanities and the Social Sciences' '1150' '2813'\n",
      "  '619']\n",
      " ...\n",
      " ['2020' 'F' 'Law' '60' '210' '62']\n",
      " ['2020' 'M' 'Sciences' '440' '1090' '471']\n",
      " ['2020' 'F' 'Sciences' '669' '1947' '730']]\n"
     ]
    }
   ],
   "source": [
    "# Add back header\n",
    "polyEdit = np.vstack((np.genfromtxt('datasets_cleaned/poly/poly_intake.csv',dtype='U64',delimiter=',')[0],polyEdit))\n",
    "# Remove all NA\n",
    "polyEdit = polyEdit[polyEdit[:,0]!='NA']\n",
    "print(polyEdit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/poly/poly_intake.csv',polyEdit,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Uni*\n",
    "\n",
    "Not much explanation to be done since its identical to what was done for the poly datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Initial Col Name   | New Col Name |\n",
    "|----------------------|------|\n",
    "| Engineering Sciences | Engineering |\n",
    "| Architecture, Building & Real Estate | Architecture and Built Environment|\n",
    "| Business & Administration | Business |\n",
    "| Accountancy | Business |\n",
    "| Information Technology | Information & Digital Technologies|\n",
    "| Fine & Applied Arts | Arts, Humanities and the Social Sciences|\n",
    "| Mass Communication | Arts, Humanities and the Social Sciences|\n",
    "| Services | Arts, Humanities and the Social Sciences|\n",
    "| Humanities & Social Sciences | Arts, Humanities and the Social Sciences|\n",
    "| Medicine | Medicine |\n",
    "| Dentistry | Dentistry |\n",
    "| Health Sciences | Health Sciences |\n",
    "| Education | Education |\n",
    "| Natural & Mathematical Sciences | Sciences |\n",
    "Natural, Physical & Mathematical Sciences | Sciences |\n",
    "| Law | Law |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniEdit = np.genfromtxt('datasets_cleaned/uni/uni_intake.csv',dtype='U64',delimiter=',',skip_header=1)\n",
    "for a in uniEdit:\n",
    "    if 'Engineering' in a[2]:\n",
    "        a[2] = 'Engineering'\n",
    "    elif 'Architecture' in a[2]:\n",
    "        a[2] = 'Architecture and Built Environment'\n",
    "    elif 'Business' in a[2] or a[2] == 'Accountancy':\n",
    "        a[2] = 'Business'\n",
    "    elif 'Information Technology' in a[2]:\n",
    "        a[2] = 'Information & Digital Technologies'\n",
    "    elif 'Applied Arts' in a[2] or a[2] == 'Mass Communication' or a[2]=='Services' or 'Humanities' in a[2]:\n",
    "        a[2] = 'Arts` Humanities and the Social Sciences'\n",
    "    elif 'Sciences' in a[2] and a[2]!= 'Health Sciences':\n",
    "        a[2] = 'Sciences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020' 'F' 'Health Sciences' '761' '2455' '522'] 15\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '929' '4109' '1022'] 16\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '2001' '8783'\n",
      " '2125'] 17\n",
      "['2020' 'M' 'Information & Digital Technologies' '2017' '6014' '970'] 18\n",
      "['2020' 'F' 'Information & Digital Technologies' '846' '2797' '397'] 19\n",
      "['2020' 'M' 'Law' '204' '916' '190'] 20\n",
      "['2020' 'F' 'Law' '259' '907' '204'] 21\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '28' '148' '39'] 22\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '142' '566' '142'] 23\n",
      "['2020' 'M' 'Medicine' '253' '1158' '208'] 24\n",
      "['2020' 'F' 'Medicine' '224' '1020' '178'] 25\n",
      "['2020' 'M' 'Sciences' '788' '3089' '801'] 26\n",
      "['2020' 'F' 'Sciences' '891' '3624' '1127'] 27\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '143' '402' '107'] 28\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '139' '412' '112'] 29\n"
     ]
    }
   ],
   "source": [
    "for i,a in enumerate(uniEdit):\n",
    "    if int(a[0])<=2018:\n",
    "        if a[1]=='MF':\n",
    "            a[1]='M'\n",
    "            a[3] = str(int(a[3])-int(uniEdit[i+1][3]))\n",
    "            a[4] = str(int(a[4])-int(uniEdit[i+1][4]))\n",
    "            a[5] = str(int(a[5])-int(uniEdit[i+1][5]))\n",
    "    else:\n",
    "        if a[1]=='MF':\n",
    "            a[1]='M'\n",
    "            # Since there are 12 different courses\n",
    "            a[3] = str(int(a[3])-int(uniEdit[i+15][3]))\n",
    "            a[4] = str(int(a[4])-int(uniEdit[i+15][4]))\n",
    "            a[5] = str(int(a[5])-int(uniEdit[i+15][5]))\n",
    "\n",
    "# Reformat data for 2019 and 2020\n",
    "counter = 0\n",
    "for i in range(len(uniEdit)):\n",
    "    if int(uniEdit[i][0])==2019:\n",
    "        if counter<15:\n",
    "            # We have to use vstack instead of concat or append since we are adding a 1d array to a 2d array (and since axis=0)\n",
    "            uniEdit = np.vstack((uniEdit[:i+1+counter],uniEdit[i+15+counter],uniEdit[i+1+counter:]))\n",
    "        # remove duplicates from 2019\n",
    "        elif counter==30:\n",
    "            uniEdit = np.delete(uniEdit,np.s_[i:i+15],0)\n",
    "        counter+=1\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(uniEdit)):\n",
    "    if int(uniEdit[i][0])==2020:\n",
    "        if counter<15:\n",
    "            uniEdit = np.vstack((uniEdit[:i+1+counter],uniEdit[i+15+counter],uniEdit[i+1+counter:]))\n",
    "        else:\n",
    "            print(uniEdit[i],counter)\n",
    "        counter+=1\n",
    "\n",
    "# since the last 12 rows are duplicates, we remove them\n",
    "uniEdit = np.delete(uniEdit,np.s_[-15:],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n"
     ]
    }
   ],
   "source": [
    "# Number of rows (+1 for header) we should get\n",
    "print((len(unique_courses))*2*(2021-2005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arts` Humanities and the Social Sciences [12, 16, 22, 28]\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '589' '1944' '401'] 1\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '42' '137' '36'] 2\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '18' '28' '0'] 3\n",
      "['2005' 'M' 'Arts` Humanities and the Social Sciences' '709' '2252' '448']\n",
      "['2005' 'F' 'Arts` Humanities and the Social Sciences' '1915' '5598'\n",
      " '1370']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [0, 4]\n",
      "['2005' 'M' 'Business' '644' '1915' '358'] 1\n",
      "['2005' 'M' 'Business' '990' '2744' '569']\n",
      "['2005' 'F' 'Business' '1431' '4830' '1393']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [42, 46, 52, 58]\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '760' '2250' '460'] 1\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '27' '130' '33'] 2\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '32' '60' '0'] 3\n",
      "['2006' 'M' 'Arts` Humanities and the Social Sciences' '915' '2663' '504']\n",
      "['2006' 'F' 'Arts` Humanities and the Social Sciences' '2139' '6288'\n",
      " '1419']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [30, 34]\n",
      "['2006' 'M' 'Business' '737' '2193' '432'] 1\n",
      "['2006' 'M' 'Business' '1114' '3218' '608']\n",
      "['2006' 'F' 'Business' '1592' '5116' '1286']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [72, 76, 82, 88]\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '756' '2491' '484'] 1\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '46' '147' '28'] 2\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '23' '83' '0'] 3\n",
      "['2007' 'M' 'Arts` Humanities and the Social Sciences' '920' '3003' '540']\n",
      "['2007' 'F' 'Arts` Humanities and the Social Sciences' '2387' '7314'\n",
      " '1305']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [60, 64]\n",
      "['2007' 'M' 'Business' '664' '2312' '491'] 1\n",
      "['2007' 'M' 'Business' '1039' '3472' '751']\n",
      "['2007' 'F' 'Business' '1694' '5277' '1467']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [102, 106, 112, 118]\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '852' '2826' '505'] 1\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '36' '145' '32'] 2\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '29' '96' '14'] 3\n",
      "['2008' 'M' 'Arts` Humanities and the Social Sciences' '1024' '3409' '582']\n",
      "['2008' 'F' 'Arts` Humanities and the Social Sciences' '2269' '7986'\n",
      " '1537']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [90, 94]\n",
      "['2008' 'M' 'Business' '593' '2425' '503'] 1\n",
      "['2008' 'M' 'Business' '1010' '3654' '798']\n",
      "['2008' 'F' 'Business' '1581' '5333' '1495']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [132, 136, 142, 148]\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '944' '3162' '573'] 1\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '66' '176' '36'] 2\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '21' '103' '13'] 3\n",
      "['2009' 'M' 'Arts` Humanities and the Social Sciences' '1152' '3850' '669']\n",
      "['2009' 'F' 'Arts` Humanities and the Social Sciences' '2428' '8496'\n",
      " '1858']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [120, 124]\n",
      "['2009' 'M' 'Business' '695' '2439' '627'] 1\n",
      "['2009' 'M' 'Business' '1174' '3851' '969']\n",
      "['2009' 'F' 'Business' '1487' '5329' '1450']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [162, 166, 172, 178]\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '884' '3319' '736'] 1\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '42' '185' '30'] 2\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '86' '161' '29'] 3\n",
      "['2010' 'M' 'Arts` Humanities and the Social Sciences' '1171' '4138' '879']\n",
      "['2010' 'F' 'Arts` Humanities and the Social Sciences' '2351' '8884'\n",
      " '1948']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [150, 154]\n",
      "['2010' 'M' 'Business' '706' '2476' '658'] 1\n",
      "['2010' 'M' 'Business' '1186' '3962' '1038']\n",
      "['2010' 'F' 'Business' '1590' '5446' '1409']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [192, 196, 202, 208]\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '793' '3242' '708'] 1\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '39' '183' '41'] 2\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '118' '252' '24'] 3\n",
      "['2011' 'M' 'Arts` Humanities and the Social Sciences' '1117' '4216' '857']\n",
      "['2011' 'F' 'Arts` Humanities and the Social Sciences' '2244' '8152'\n",
      " '2087']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [180, 184]\n",
      "['2011' 'M' 'Business' '727' '2543' '633'] 1\n",
      "['2011' 'M' 'Business' '1209' '4170' '965']\n",
      "['2011' 'F' 'Business' '1528' '5481' '1451']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [222, 226, 232, 238]\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '838' '3327' '737'] 1\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '37' '184' '37'] 2\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '127' '345' '54'] 3\n",
      "['2012' 'M' 'Arts` Humanities and the Social Sciences' '1168' '4442' '936']\n",
      "['2012' 'F' 'Arts` Humanities and the Social Sciences' '2392' '8717'\n",
      " '1911']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [210, 214]\n",
      "['2012' 'M' 'Business' '743' '2705' '572'] 1\n",
      "['2012' 'M' 'Business' '1274' '4390' '1019']\n",
      "['2012' 'F' 'Business' '1671' '5684' '1414']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [252, 256, 262, 268]\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '1054' '3550' '818'] 1\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '51' '173' '62'] 2\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '139' '371' '136'] 3\n",
      "['2013' 'M' 'Arts` Humanities and the Social Sciences' '1444' '4722'\n",
      " '1154']\n",
      "['2013' 'F' 'Arts` Humanities and the Social Sciences' '2716' '9039'\n",
      " '2363']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [240, 244]\n",
      "['2013' 'M' 'Business' '803' '2782' '693'] 1\n",
      "['2013' 'M' 'Business' '1309' '4550' '1092']\n",
      "['2013' 'F' 'Business' '1656' '5680' '1585']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [282, 286, 292, 298]\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '1022' '3756' '803'] 1\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '46' '174' '44'] 2\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '54' '286' '135'] 3\n",
      "['2014' 'M' 'Arts` Humanities and the Social Sciences' '1309' '4857'\n",
      " '1147']\n",
      "['2014' 'F' 'Arts` Humanities and the Social Sciences' '2619' '9420'\n",
      " '2181']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [270, 274]\n",
      "['2014' 'M' 'Business' '837' '2980' '631'] 1\n",
      "['2014' 'M' 'Business' '1492' '4892' '1104']\n",
      "['2014' 'F' 'Business' '1925' '6053' '1495']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [312, 316, 322, 328]\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '1033' '3861' '743'] 1\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '40' '174' '42'] 2\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '105' '352' '154'] 3\n",
      "['2015' 'M' 'Arts` Humanities and the Social Sciences' '1400' '5052'\n",
      " '1126']\n",
      "['2015' 'F' 'Arts` Humanities and the Social Sciences' '2677' '9963'\n",
      " '2001']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [300, 304]\n",
      "['2015' 'M' 'Business' '848' '3111' '771'] 1\n",
      "['2015' 'M' 'Business' '1488' '5150' '1251']\n",
      "['2015' 'F' 'Business' '2102' '6711' '1404']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [342, 346, 352, 358]\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '1014' '4046' '803'] 1\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '42' '178' '35'] 2\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '91' '355' '84'] 3\n",
      "['2016' 'M' 'Arts` Humanities and the Social Sciences' '1308' '5249'\n",
      " '1095']\n",
      "['2016' 'F' 'Arts` Humanities and the Social Sciences' '2760' '10385'\n",
      " '2267']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [330, 334]\n",
      "['2016' 'M' 'Business' '959' '3284' '751'] 1\n",
      "['2016' 'M' 'Business' '1568' '5465' '1190']\n",
      "['2016' 'F' 'Business' '2149' '7139' '1633']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [372, 376, 382, 388]\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '1105' '4185' '945'] 1\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '54' '182' '48'] 2\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '81' '335' '99'] 3\n",
      "['2017' 'M' 'Arts` Humanities and the Social Sciences' '1428' '5374'\n",
      " '1259']\n",
      "['2017' 'F' 'Arts` Humanities and the Social Sciences' '2600' '10408'\n",
      " '2465']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [360, 364]\n",
      "['2017' 'M' 'Business' '988' '3500' '755'] 1\n",
      "['2017' 'M' 'Business' '1662' '5763' '1308']\n",
      "['2017' 'F' 'Business' '2239' '7628' '1661']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [402, 406, 412, 418]\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '1041' '4220' '945'] 1\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '42' '178' '46'] 2\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '118' '353' '98'] 3\n",
      "['2018' 'M' 'Arts` Humanities and the Social Sciences' '1364' '5413'\n",
      " '1269']\n",
      "['2018' 'F' 'Arts` Humanities and the Social Sciences' '2824' '10683'\n",
      " '2491']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [390, 394]\n",
      "['2018' 'M' 'Business' '1084' '3741' '837'] 1\n",
      "['2018' 'M' 'Business' '1774' '6062' '1416']\n",
      "['2018' 'F' 'Business' '2432' '8175' '1767']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [432, 436, 442, 448]\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '1012' '4227' '978'] 1\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '24' '161' '41'] 2\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '116' '363' '95'] 3\n",
      "['2019' 'M' 'Arts` Humanities and the Social Sciences' '1326' '5388'\n",
      " '1295']\n",
      "['2019' 'F' 'Arts` Humanities and the Social Sciences' '2794' '10862'\n",
      " '2551']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [420, 424]\n",
      "['2019' 'M' 'Business' '1251' '4134' '847'] 1\n",
      "['2019' 'M' 'Business' '1904' '6461' '1435']\n",
      "['2019' 'F' 'Business' '2639' '8695' '2008']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Arts` Humanities and the Social Sciences [462, 466, 472, 478]\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '929' '4109' '1022'] 1\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '28' '148' '39'] 2\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '143' '402' '107'] 3\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '1233' '5265'\n",
      " '1325']\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '2533' '10672'\n",
      " '2651']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "Business [450, 454]\n",
      "['2020' 'M' 'Business' '1339' '4591' '896'] 1\n",
      "['2020' 'M' 'Business' '1895' '6814' '1495']\n",
      "['2020' 'F' 'Business' '2851' '9443' '2021']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n",
      "['NA' 'NA' 'NA' 'NA' 'NA' 'NA']\n"
     ]
    }
   ],
   "source": [
    "# Add the data to the dictionary\n",
    "for year in range(2005,2021):\n",
    "    \n",
    "    # Create a dictionary to store the data\n",
    "    course_dict = {}\n",
    "    for course in unique_courses:\n",
    "        course_dict[course] = []\n",
    "\n",
    "    for i,a in enumerate(uniEdit):\n",
    "        if a[2] in course_dict and float(a[0])==year:\n",
    "            if a[1]=='M':\n",
    "                course_dict[a[2]].append(i)\n",
    "\n",
    "\n",
    "    for k,v in course_dict.items():\n",
    "        if len(v)>1:\n",
    "            print(k,v)\n",
    "            for j,n in enumerate(v):\n",
    "                # Combine the data into one numpy array\n",
    "                if j>0:\n",
    "                    print(uniEdit[n],j)\n",
    "\n",
    "                    # For males\n",
    "                    uniEdit[v[0]][3] = str(int(uniEdit[v[0]][3])+int(uniEdit[n][3]))\n",
    "                    uniEdit[v[0]][4] = str(int(uniEdit[v[0]][4])+int(uniEdit[n][4]))\n",
    "                    uniEdit[v[0]][5] = str(int(uniEdit[v[0]][5])+int(uniEdit[n][5]))\n",
    "\n",
    "                    # Repeat for Females\n",
    "                    uniEdit[v[0]+1][3] = str(int(uniEdit[v[0]+1][3])+int(uniEdit[n+1][3]))\n",
    "                    uniEdit[v[0]+1][4] = str(int(uniEdit[v[0]+1][4])+int(uniEdit[n+1][4]))\n",
    "                    uniEdit[v[0]+1][5] = str(int(uniEdit[v[0]+1][5])+int(uniEdit[n+1][5]))\n",
    "\n",
    "\n",
    "                    # Remove the duplicates later\n",
    "                    uniEdit[n] = np.array(['NA','NA','NA','NA','NA','NA'])\n",
    "                    uniEdit[n+1] = np.array(['NA','NA','NA','NA','NA','NA'])\n",
    "            \n",
    "            # No need to get average since these are enrollment, intake and grad numbers (not percentages like before)\n",
    "\n",
    "            \n",
    "            for n in v:\n",
    "                print(uniEdit[n])\n",
    "                print(uniEdit[n+1])\n",
    "    year+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['year' 'sex' 'course' 'intake' 'enrolment' 'graduates']\n",
      " ['2005' 'M' 'Business' '990' '2744' '569']\n",
      " ['2005' 'F' 'Business' '1431' '4830' '1393']\n",
      " ...\n",
      " ['2020' 'F' 'Medicine' '224' '1020' '178']\n",
      " ['2020' 'M' 'Sciences' '788' '3089' '801']\n",
      " ['2020' 'F' 'Sciences' '891' '3624' '1127']]\n"
     ]
    }
   ],
   "source": [
    "# Add back header\n",
    "uniEdit = np.vstack((np.genfromtxt('datasets_cleaned/uni/uni_intake.csv',dtype='U64',delimiter=',')[0],uniEdit))\n",
    "# Remove all NA\n",
    "uniEdit = uniEdit[uniEdit[:,0]!='NA']\n",
    "print(uniEdit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/uni/uni_intake.csv',uniEdit,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b40f880619167c1897eb19ed28404e44ef5681baa2b94c6a6ce5dad7d6c8be5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
