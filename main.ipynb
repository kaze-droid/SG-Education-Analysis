{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done By: **Ryan Yeo**\n",
    "\n",
    "Class: **DAAA/FT/1B/01**\n",
    "\n",
    "Admin Num: **P2214452**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'datasets_cleaned'\n"
     ]
    }
   ],
   "source": [
    "# Create directory if it exists print err\n",
    "try:\n",
    "    os.mkdir('datasets_cleaned')\n",
    "except OSError as error:\n",
    "    print(error)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean employment dataset\n",
    "\n",
    "# Note:\n",
    "# We cannot use genfromtxt directly because it reads commas contained in strings(unlike csvreader and pd.read_csv) \n",
    "# To avoid that, we first read in all the data seperated by a newline before processing it\n",
    "\n",
    "dirtyData_17to19 = np.genfromtxt('datasets_src/employment/emp_17to19.csv', dtype=\"U64\",delimiter=\"\\n\")\n",
    "dirtyData_19to21 = np.genfromtxt('datasets_src/employment/emp_19to21.csv', dtype=\"U64\",delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and clean the dataset so that it can be written to datasets_cleaned\n",
    "def cleanData(dirtyArr):\n",
    "    employ_arr = []\n",
    "    for i in dirtyArr:\n",
    "        _ = []\n",
    "        inQuotes = False\n",
    "        for j,n in enumerate(i):\n",
    "            if n=='\\\"':\n",
    "                # If opening quotes => True elif closing quotes => False\n",
    "                inQuotes=not inQuotes\n",
    "            if n==',' and inQuotes:\n",
    "                # If it's used in a string, change it to a backtick\n",
    "                # This is for the sole purpose of not causing any error when reading as csv\n",
    "                # When printing from this column, backticks will be changed back to commas\n",
    "                if i[j+1]==' ':\n",
    "                    _.append('`')\n",
    "                # If it's used in money, (e.g. $3,600) just remove the comma\n",
    "                else:\n",
    "                    _.append('')\n",
    "            else:\n",
    "                _.append(n)\n",
    "        employ_arr.append(\"\".join(_))\n",
    "    employ_arr = np.array(employ_arr)\n",
    "    return employ_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can delete one set of 2019 data since we don't need duplicates from both arr\n",
    "cleaned_17to19 = cleanData(dirtyData_17to19)[:-((len(cleanData(dirtyData_17to19))-1)//3)]\n",
    "\n",
    "# We can also delete the header for the second arr\n",
    "cleaned_19to21 = cleanData(dirtyData_19to21)[1:]\n",
    "\n",
    "cleaned = np.concatenate((cleaned_17to19,cleaned_19to21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'datasets_cleaned/employment'\n"
     ]
    }
   ],
   "source": [
    "# Now we can write back the data into datasets_cleaned\n",
    "try:\n",
    "    os.mkdir('datasets_cleaned/employment')\n",
    "except OSError as error:\n",
    "    print(error)  \n",
    "\n",
    "cleaned.tofile('datasets_cleaned/employment/employ.csv',sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However at this point our data is still not in the right format yet\n",
    "\n",
    "Due to our need to manipulate and remove commas that were not seperators, \n",
    "we had to cast each row as a string datatype\n",
    "\n",
    "When writing to a csv file, it will cause quotation marks to appear for each row\n",
    "Since we don't want that to affect main.ipynb, we would have to reopen the file the format it\n",
    "\n",
    "This time since we changed the commas, it would be less of a hassle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='U64',delimiter=',')\n",
    "# Reformat array\n",
    "f = np.char.replace(f,'\\'','')  \n",
    "f = np.char.replace(f,'\\\"','')\n",
    "\n",
    "# We can also remove the '$' and the '%' in the meantime so that we can easily convert into float later\n",
    "f = np.char.replace(f,'$','')\n",
    "f = np.char.replace(f,'%','')\n",
    "\n",
    "\n",
    "# Delete file so that savetxt does not replace chars\n",
    "os.remove('datasets_cleaned/employment/employ.csv')\n",
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/employment/employ.csv',f,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake\n",
    "Now we repeat the entire process again for the different intakes (_This includes Poly and Uni_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior to this, U64 was used and it accidentally cut off data from Poly Intake\n",
    "dirtyPoly = np.genfromtxt('datasets_src/poly_intake/polytechnics-intake-enrolment-and-graduates-by-course.csv', dtype=\"U128\",delimiter=\"\\n\")\n",
    "dirtyUni = np.genfromtxt('datasets_src/uni_intake/universities-intake-enrolment-and-graduates-by-course.csv',dtype=\"U128\",delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is no salary data, we are just replacing commas with backticks using cleanData\n",
    "cleanPoly = cleanData(dirtyPoly)\n",
    "cleanUni = cleanData(dirtyUni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'datasets_cleaned/poly'\n"
     ]
    }
   ],
   "source": [
    "# Poly\n",
    "try:\n",
    "    os.mkdir('datasets_cleaned/poly')\n",
    "except OSError as error:\n",
    "    print(error)  \n",
    "\n",
    "# Generates an error if you already have the file opened elsewhere\n",
    "cleanPoly.tofile('datasets_cleaned/poly/poly_intake.csv',sep='\\n')\n",
    "\n",
    "# Since now each string is one cell of data and not one row, we can go back to using U64\n",
    "f=np.genfromtxt('datasets_cleaned/poly/poly_intake.csv',dtype='U64',delimiter=',')\n",
    "# Reformat array\n",
    "f = np.char.replace(f,'\\'','')  \n",
    "f = np.char.replace(f,'\\\"','')\n",
    "\n",
    "# Delete file so that savetxt does not replace chars\n",
    "os.remove('datasets_cleaned/poly/poly_intake.csv')\n",
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/poly/poly_intake.csv',f,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'datasets_cleaned/uni'\n"
     ]
    }
   ],
   "source": [
    "# Uni\n",
    "try:\n",
    "    os.mkdir('datasets_cleaned/uni')\n",
    "except OSError as error:\n",
    "    print(error)  \n",
    "\n",
    "# Generates an error if you already have the file opened elsewhere\n",
    "cleanUni.tofile('datasets_cleaned/uni/uni_intake.csv',sep='\\n')\n",
    "\n",
    "f=np.genfromtxt('datasets_cleaned/uni/uni_intake.csv',dtype='U64',delimiter=',')\n",
    "# Reformat array\n",
    "f = np.char.replace(f,'\\'','')  \n",
    "f = np.char.replace(f,'\\\"','')\n",
    "\n",
    "# Delete file so that savetxt does not replace chars\n",
    "os.remove('datasets_cleaned/uni/uni_intake.csv')\n",
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/uni/uni_intake.csv',f,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "employEdit = np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='U64',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Initial Col Name   | New Col Name |\n",
    "|----------------------|------|\n",
    "| Engineering | Engineering |\n",
    "| Architecture | Architecture and Built Environment|\n",
    "| Business | Business |\n",
    "| Information & Digital Technologies | Information & Digital Technologies|\n",
    "| Medicine | Medicine |\n",
    "| Arts, Design & Medias | Arts, Humanities and the Social Sciences|\n",
    "| Dentistry | Dentistry |\n",
    "| Built environment | Architecture and Built Environment|\n",
    "|Yale-NUS| *Removed*|\n",
    "|Biomedical Sciences| Health Sciences |\n",
    "| Pharmacy | Health Sciences |\n",
    "| Education (NIE) | Education |\n",
    "| Music | Arts, Humanities and the Social Sciences|\n",
    "| Humanities & Social Sciences | Arts, Humanities and the Social Sciences|\n",
    "| Health Sciences | Health Sciences |\n",
    "| Sciences | Sciences |\n",
    "| Law | Law |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['year' 'course_cluster' 'employed' 'ft_employment'\n",
      "  'gross median salary']\n",
      " ['2017' 'Arts` Humanities and the Social Sciences' '91.40' '65.60'\n",
      "  '2944']\n",
      " ['2017' 'Architecture and Built Environment' '92.70' '86.50' '3200']\n",
      " ['2017' 'Business' '95.40' '89.50' '3200']\n",
      " ['2017' 'Dentistry' '100' '100.00' '4050']\n",
      " ['2017' 'Education' '100' '100.00' '3600']\n",
      " ['2017' 'Engineering' '86.70' '79.50' '3500']\n",
      " ['2017' 'Health Sciences' '96.70' '93.70' '3450']\n",
      " ['2017' 'Arts` Humanities and the Social Sciences' '85.70' '70.10'\n",
      "  '3300']\n",
      " ['2017' 'Information & Digital Technologies' '94.60' '90.10' '4000']\n",
      " ['2017' 'Arts` Humanities and the Social Sciences' '73.30' '26.70'\n",
      "  '2225']\n",
      " ['2017' 'Sciences' '82.60' '65.30' '3250']\n",
      " ['2017' 'Architecture and Built Environment' '91.30' '86.40' '4000']\n",
      " ['2017' 'Health Sciences' '92.00' '80.00' '2950']\n",
      " ['2017' 'Law' '96.40' '92.80' '5000']\n",
      " ['2017' 'Medicine' '100.00' '100.00' '5000']\n",
      " ['2017' 'Health Sciences' '99.10' '94.50' '3600']\n",
      " ['2018' 'Arts` Humanities and the Social Sciences' '89.10' '68.30'\n",
      "  '3000']\n",
      " ['2018' 'Architecture and Built Environment' '91.60' '85.90' '3400']\n",
      " ['2018' 'Business' '94.40' '89.10' '3400']\n",
      " ['2018' 'Dentistry' '100.00' '100.00' '4050']\n",
      " ['2018' 'Education' '100.00' '99.40' '3800']\n",
      " ['2018' 'Engineering' '89.90' '83.80' '3600']\n",
      " ['2018' 'Health Sciences' '96.70' '89.40' '3450']\n",
      " ['2018' 'Arts` Humanities and the Social Sciences' '87.30' '72.10'\n",
      "  '3400']\n",
      " ['2018' 'Information & Digital Technologies' '95.00' '92.00' '4022']\n",
      " ['2018' 'Arts` Humanities and the Social Sciences' '81.00' '23.80'\n",
      "  '1800']\n",
      " ['2018' 'Sciences' '84.40' '68.80' '3313']\n",
      " ['2018' 'Architecture and Built Environment' '96.20' '92.40' '4000']\n",
      " ['2018' 'Health Sciences' '90.90' '81.80' '3000']\n",
      " ['2018' 'Law' '95.30' '91.80' '5000']\n",
      " ['2018' 'Medicine' 'NA' 'NA' 'NA']\n",
      " ['2018' 'Health Sciences' '96.60' '93.20' '3650']\n",
      " ['2019' 'Arts` Humanities and the Social Sciences' '87.30' '62.40'\n",
      "  '3200']\n",
      " ['2019' 'Architecture and Built Environment' '92.60' '87.30' '3500']\n",
      " ['2019' 'Business' '94.60' '88.80' '3500']\n",
      " ['2019' 'Dentistry' '100' '97.30' '4200']\n",
      " ['2019' 'Education' '100' '100.00' '3800']\n",
      " ['2019' 'Engineering' '88.40' '83.30' '3750']\n",
      " ['2019' 'Health Sciences' '97.10' '88.40' '3500']\n",
      " ['2019' 'Arts` Humanities and the Social Sciences' '88.00' '74.50'\n",
      "  '3500']\n",
      " ['2019' 'Information & Digital Technologies' '95.40' '92.70' '4400']\n",
      " ['2019' 'Arts` Humanities and the Social Sciences' '82.60' '39.10'\n",
      "  '3500']\n",
      " ['2019' 'Sciences' '86.90' '71.50' '3500']\n",
      " ['2019' 'Architecture and Built Environment' '100.00' '96.00' '4100']\n",
      " ['2019' 'Health Sciences' '95.20' '85.70' '3000']\n",
      " ['2019' 'Law' '97.00' '95.00' '5000']\n",
      " ['2019' 'Medicine' '99.60' '99.60' '5300']\n",
      " ['2019' 'Health Sciences' '100' '95.50' '3750']\n",
      " ['2020' 'Arts` Humanities and the Social Sciences' '92.30' '50.10'\n",
      "  '3300']\n",
      " ['2020' 'Architecture and Built Environment' '93.90' '72.50' '3500']\n",
      " ['2020' 'Business' '95.30' '76.00' '3500']\n",
      " ['2020' 'Dentistry' '100.00' '100.00' '4200']\n",
      " ['2020' 'Education' '100.00' '99.10' '3800']\n",
      " ['2020' 'Engineering' '93.60' '71.60' '3900']\n",
      " ['2020' 'Health Sciences' '97.40' '83.30' '3500']\n",
      " ['2020' 'Arts` Humanities and the Social Sciences' '92.10' '61.80'\n",
      "  '3500']\n",
      " ['2020' 'Information & Digital Technologies' '94.80' '87.30' '4760']\n",
      " ['2020' 'Arts` Humanities and the Social Sciences' '69.20' '15.40'\n",
      "  '3275']\n",
      " ['2020' 'Sciences' '91.60' '55.40' '3500']\n",
      " ['2020' 'Architecture and Built Environment' '94.00' '91.00' '4000']\n",
      " ['2020' 'Health Sciences' '94.70' '84.20' '3000']\n",
      " ['2020' 'Law' '93.40' '88.60' '5000']\n",
      " ['2020' 'Medicine' '100.00' '100.00' '5250']\n",
      " ['2020' 'Health Sciences' '99.30' '93.70' '3700']\n",
      " ['2021' 'Arts` Humanities and the Social Sciences' '92.60' '69.30'\n",
      "  '3500']\n",
      " ['2021' 'Architecture and Built Environment' '94.50' '88.90' '3600']\n",
      " ['2021' 'Business' '97.00' '88.70' '3723']\n",
      " ['2021' 'Dentistry' '100.00' '100.00' '4200']\n",
      " ['2021' 'Education' '100.00' '100.00' '3798']\n",
      " ['2021' 'Engineering' '94.00' '86.90' '3900']\n",
      " ['2021' 'Health Sciences' '95.70' '85.90' '3635']\n",
      " ['2021' 'Arts` Humanities and the Social Sciences' '91.20' '75.60'\n",
      "  '3550']\n",
      " ['2021' 'Information & Digital Technologies' '97.80' '93.70' '5000']\n",
      " ['2021' 'Arts` Humanities and the Social Sciences' '82.40' '35.30'\n",
      "  '3100']\n",
      " ['2021' 'Sciences' '91.70' '75.80' '3600']\n",
      " ['2021' 'Architecture and Built Environment' '97.70' '96.60' '4000']\n",
      " ['2021' 'Health Sciences' '90.90' '77.30' '3100']\n",
      " ['2021' 'Law' '97.90' '95.50' '5600']\n",
      " ['2021' 'Medicine' 'NA' 'NA' 'NA']\n",
      " ['2021' 'Health Sciences' '95.90' '91.90' '3915']]\n"
     ]
    }
   ],
   "source": [
    "# Rename course name to match the other datasets\n",
    "for a in employEdit:\n",
    "    if a[1]=='Architecture' or a[1]=='Built Environment':\n",
    "        a[1] = 'Architecture and Built Environment'\n",
    "    elif a[1]=='Arts` Design & Media' or a[1]=='Music' or a[1]=='Humanities & Social Sciences':\n",
    "        a[1] = 'Arts` Humanities and the Social Sciences'\n",
    "    elif a[1]=='Biomedical Sciences' or a[1]=='Pharmacy' or a[1]=='Health Sciences':\n",
    "        a[1] = 'Health Sciences'\n",
    "    elif a[1] == 'Education(NIE)':\n",
    "        a[1] = 'Education'\n",
    "\n",
    "# Remove row if it contains Yale-NUS\n",
    "counter=0\n",
    "for i,a in enumerate(employEdit):\n",
    "    if a[1]=='Yale-NUS':\n",
    "        employEdit = np.delete(employEdit,i-counter,0)\n",
    "        counter+=1\n",
    "\n",
    "print(employEdit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete file so that savetxt does not replace chars\n",
    "os.remove('datasets_cleaned/employment/employ.csv')\n",
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/employment/employ.csv',employEdit,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course cluster: Medicine, year: 2018, column: employed\n",
      "course cluster: Medicine, year: 2018, column: ft_employment\n",
      "course cluster: Medicine, year: 2018, column: gross median salary\n",
      "course cluster: Medicine, year: 2021, column: employed\n",
      "course cluster: Medicine, year: 2021, column: ft_employment\n",
      "course cluster: Medicine, year: 2021, column: gross median salary\n"
     ]
    }
   ],
   "source": [
    "# Read csv file\n",
    "employArr = np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='float',delimiter=',',skip_header=1,usecols=(0,2,3,4))\n",
    "col_header = np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='U64',delimiter=',',usecols=(0,2,3,4))[0]\n",
    "employCourse = np.genfromtxt('datasets_cleaned/employment/employ.csv',dtype='U64',delimiter=',',skip_header=1,usecols=(1))\n",
    "# Since we have to use isnan, setting names=True is not an option since the string cannot be set to float\n",
    "# As such we make our own artificial columns using dictionary and 'col_header'\n",
    "employNames = {}\n",
    "for i,n in enumerate(col_header):\n",
    "    employNames[n]=i\n",
    "\n",
    "# Get all missing data\n",
    "missing = np.argwhere(np.isnan(employArr))\n",
    "for i in missing:\n",
    "# Get col name by swapping key and values inside employNames\n",
    "    print(f\"course cluster: {employCourse[i[0]]}, year: {int(employArr[i[0]][0])}, column: {({v:k for k,v in employNames.items()})[i[1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the missing data is for the course cluster \"Medicine\" and for year 2018 and 2021\n",
    "\n",
    "Since:\n",
    "1. The missing data is not randomly distributed (its just for medicine)\n",
    "2. They are accounted for by other data in our datasets (Medicine data of salary and employment percentages from year 2017, 2019 and 2021 are likely to be similar to 2017,2019 and 2020)\n",
    "\n",
    "The missing data is Missing At Random\n",
    "\n",
    "*In the PDF by MOE, it is explained that the missing data is due to insufficient graduates/response rate*\n",
    "\n",
    "Since the data is MAR, we can either choose to impute or remove the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 100.   100.  5000.    99.6   99.6 5300.   100.   100.  5250. ]\n",
      "[2018.     99.87   99.87 5183.33]\n",
      "[2021.     99.87   99.87 5183.33]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Mean imputation\n",
    "\n",
    "# Get data for medicine from 2017,2019 and 2021\n",
    "dataForImpute = np.array([])\n",
    "for i,j in zip(employArr,employCourse):\n",
    "    if i[employNames[\"year\"]] in [2017,2019,2020] and j=='Medicine':\n",
    "        dataForImpute = np.concatenate((dataForImpute,i[1:]))\n",
    "\n",
    "print(dataForImpute)\n",
    "\n",
    "ImputeData = np.zeros((3,3))\n",
    "\n",
    "# Reformat data(by grouping similar cols together) so that np.mean() can be used\n",
    "for iter in range(3):\n",
    "    ImputeData[iter] = np.array([n for i,n in enumerate(dataForImpute) if i%3==iter])\n",
    "\n",
    "# Replace nan values with mean\n",
    "for i,n in enumerate(ImputeData):\n",
    "    employArr[missing[0][0]][i+1] = round(n.mean(),2)\n",
    "    employArr[missing[3][0]][i+1] = round(n.mean(),2)\n",
    "\n",
    "print(employArr[missing[0][0]])\n",
    "print(employArr[missing[3][0]])\n",
    "\n",
    "# If imputation was done correctly, the value of this should be 0\n",
    "print(len(np.argwhere(np.isnan(employArr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Initial Col Name   | New Col Name |\n",
    "|----------------------|------|\n",
    "| Engineering Sciences | Engineering |\n",
    "| Architecture, Building & Real Estate | Architecture and Built Environment|\n",
    "| Business & Administration | Business |\n",
    "| Information Technology | Information & Digital Technologies|\n",
    "| Applied Arts | Arts, Humanities and the Social Sciences|\n",
    "| Mass Communication | Arts, Humanities and the Social Sciences|\n",
    "| Services | Arts, Humanities and the Social Sciences|\n",
    "| Humanities & Social Sciences | Arts, Humanities and the Social Sciences|\n",
    "| Health Sciences | Health Sciences |\n",
    "| Education | Education |\n",
    "| Natural & Mathematical Sciences | Sciences |\n",
    "Natural, Physical & Mathematical Sciences | Sciences |\n",
    "| Law | Law |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyEdit = np.genfromtxt('datasets_cleaned/poly/poly_intake.csv',dtype='U64',delimiter=',',skip_header=1)\n",
    "for a in polyEdit:\n",
    "    if 'Engineering' in a[2]:\n",
    "        a[2] = 'Engineering'\n",
    "    elif 'Architecture' in a[2]:\n",
    "        a[2] = 'Architecture and Built Environment'\n",
    "    elif 'Business' in a[2]:\n",
    "        a[2] = 'Business'\n",
    "    elif 'Information Technology' in a[2]:\n",
    "        a[2] = 'Information & Digital Technologies'\n",
    "    elif a[2] == 'Applied Arts' or a[2] == 'Mass Communication' or a[2]=='Services' or 'Humanities' in a[2]:\n",
    "        a[2] = 'Arts` Humanities and the Social Sciences'\n",
    "    elif 'Sciences' in a[2] and a[2]!= 'Health Sciences':\n",
    "        a[2] = 'Sciences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '70' '211' '89'] 12\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '228' '698' '259'] 13\n",
      "['2020' 'M' 'Information & Digital Technologies' '1883' '5824' '1808'] 14\n",
      "['2020' 'F' 'Information & Digital Technologies' '637' '2173' '802'] 15\n",
      "['2020' 'M' 'Law' '48' '118' '31'] 16\n",
      "['2020' 'F' 'Law' '60' '210' '62'] 17\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '134' '458' '159'] 18\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '415' '1334' '461'] 19\n",
      "['2020' 'M' 'Sciences' '440' '1090' '471'] 20\n",
      "['2020' 'F' 'Sciences' '669' '1947' '730'] 21\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '416' '1706' '526'] 22\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '375' '1222' '482'] 23\n"
     ]
    }
   ],
   "source": [
    "# remove all gender with MF and replace it with M (by taking values from MF-values from F)\n",
    "# from 2018 (inclusive and before), the data is stored as follows:\n",
    "# MF,course1\n",
    "# F,course1\n",
    "# MF,course2\n",
    "# F,course2\n",
    "\n",
    "# after 2018, the data is stored as follows:\n",
    "# MF,course1\n",
    "# MF,course2\n",
    "# F,course1\n",
    "# F,course2\n",
    "\n",
    "for i,a in enumerate(polyEdit):\n",
    "    if int(a[0])<=2018:\n",
    "        if a[1]=='MF':\n",
    "            a[1]='M'\n",
    "            a[3] = str(int(a[3])-int(polyEdit[i+1][3]))\n",
    "            a[4] = str(int(a[4])-int(polyEdit[i+1][4]))\n",
    "            a[5] = str(int(a[5])-int(polyEdit[i+1][5]))\n",
    "    else:\n",
    "        if a[1]=='MF':\n",
    "            a[1]='M'\n",
    "            # Since there are 12 different courses\n",
    "            a[3] = str(int(a[3])-int(polyEdit[i+12][3]))\n",
    "            a[4] = str(int(a[4])-int(polyEdit[i+12][4]))\n",
    "            a[5] = str(int(a[5])-int(polyEdit[i+12][5]))\n",
    "\n",
    "# Reformat data for 2019 and 2020\n",
    "counter = 0\n",
    "for i in range(len(polyEdit)):\n",
    "    if int(polyEdit[i][0])==2019:\n",
    "        if counter<12:\n",
    "            # We have to use vstack instead of concat or append since we are adding a 1d array to a 2d array (and since axis=0)\n",
    "            polyEdit = np.vstack((polyEdit[:i+1+counter],polyEdit[i+12+counter],polyEdit[i+1+counter:]))\n",
    "        # remove duplicates from 2019\n",
    "        elif counter==24:\n",
    "            polyEdit = np.delete(polyEdit,np.s_[i:i+12],0)\n",
    "        counter+=1\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(polyEdit)):\n",
    "    if int(polyEdit[i][0])==2020:\n",
    "        if counter<12:\n",
    "            polyEdit = np.vstack((polyEdit[:i+1+counter],polyEdit[i+12+counter],polyEdit[i+1+counter:]))\n",
    "        else:\n",
    "            print(polyEdit[i],counter)\n",
    "        counter+=1\n",
    "\n",
    "# since the last 12 rows are duplicates, we remove them\n",
    "polyEdit = np.delete(polyEdit,np.s_[-12:],0)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['year' 'sex' 'course' 'intake' 'enrolment' 'graduates']\n",
      " ['2005' 'M' 'Arts` Humanities and the Social Sciences' '441' '1055'\n",
      "  '248']\n",
      " ['2005' 'F' 'Arts` Humanities and the Social Sciences' '687' '1538'\n",
      "  '302']\n",
      " ...\n",
      " ['2020' 'F' 'Sciences' '669' '1947' '730']\n",
      " ['2020' 'M' 'Arts` Humanities and the Social Sciences' '416' '1706'\n",
      "  '526']\n",
      " ['2020' 'F' 'Arts` Humanities and the Social Sciences' '375' '1222'\n",
      "  '482']]\n"
     ]
    }
   ],
   "source": [
    "polyEdit = np.vstack((np.genfromtxt('datasets_cleaned/poly/poly_intake.csv',dtype='U64',delimiter=',')[0],polyEdit))\n",
    "print(polyEdit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete file so that savetxt does not replace chars\n",
    "os.remove('datasets_cleaned/poly/poly_intake.csv')\n",
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/poly/poly_intake.csv',polyEdit,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Initial Col Name   | New Col Name |\n",
    "|----------------------|------|\n",
    "| Engineering Sciences | Engineering |\n",
    "| Architecture, Building & Real Estate | Architecture and Built Environment|\n",
    "| Business & Administration | Business |\n",
    "| Accountancy | Business |\n",
    "| Information Technology | Information & Digital Technologies|\n",
    "| Fine & Applied Arts | Arts, Humanities and the Social Sciences|\n",
    "| Mass Communication | Arts, Humanities and the Social Sciences|\n",
    "| Services | Arts, Humanities and the Social Sciences|\n",
    "| Humanities & Social Sciences | Arts, Humanities and the Social Sciences|\n",
    "| Medicine | Medicine |\n",
    "| Dentistry | Dentistry |\n",
    "| Health Sciences | Health Sciences |\n",
    "| Education | Education |\n",
    "| Natural & Mathematical Sciences | Sciences |\n",
    "Natural, Physical & Mathematical Sciences | Sciences |\n",
    "| Law | Law |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniEdit = np.genfromtxt('datasets_cleaned/uni/uni_intake.csv',dtype='U64',delimiter=',',skip_header=1)\n",
    "for a in uniEdit:\n",
    "    if 'Engineering' in a[2]:\n",
    "        a[2] = 'Engineering'\n",
    "    elif 'Architecture' in a[2]:\n",
    "        a[2] = 'Architecture and Built Environment'\n",
    "    elif 'Business' in a[2] or a[2] == 'Accountancy':\n",
    "        a[2] = 'Business'\n",
    "    elif 'Information Technology' in a[2]:\n",
    "        a[2] = 'Information & Digital Technologies'\n",
    "    elif 'Applied Arts' in a[2] or a[2] == 'Mass Communication' or a[2]=='Services' or 'Humanities' in a[2]:\n",
    "        a[2] = 'Arts` Humanities and the Social Sciences'\n",
    "    elif 'Sciences' in a[2] and a[2]!= 'Health Sciences':\n",
    "        a[2] = 'Sciences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020' 'F' 'Health Sciences' '761' '2455' '522'] 15\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '929' '4109' '1022'] 16\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '2001' '8783'\n",
      " '2125'] 17\n",
      "['2020' 'M' 'Information & Digital Technologies' '2017' '6014' '970'] 18\n",
      "['2020' 'F' 'Information & Digital Technologies' '846' '2797' '397'] 19\n",
      "['2020' 'M' 'Law' '204' '916' '190'] 20\n",
      "['2020' 'F' 'Law' '259' '907' '204'] 21\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '28' '148' '39'] 22\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '142' '566' '142'] 23\n",
      "['2020' 'M' 'Medicine' '253' '1158' '208'] 24\n",
      "['2020' 'F' 'Medicine' '224' '1020' '178'] 25\n",
      "['2020' 'M' 'Sciences' '788' '3089' '801'] 26\n",
      "['2020' 'F' 'Sciences' '891' '3624' '1127'] 27\n",
      "['2020' 'M' 'Arts` Humanities and the Social Sciences' '143' '402' '107'] 28\n",
      "['2020' 'F' 'Arts` Humanities and the Social Sciences' '139' '412' '112'] 29\n"
     ]
    }
   ],
   "source": [
    "for i,a in enumerate(uniEdit):\n",
    "    if int(a[0])<=2018:\n",
    "        if a[1]=='MF':\n",
    "            a[1]='M'\n",
    "            a[3] = str(int(a[3])-int(uniEdit[i+1][3]))\n",
    "            a[4] = str(int(a[4])-int(uniEdit[i+1][4]))\n",
    "            a[5] = str(int(a[5])-int(uniEdit[i+1][5]))\n",
    "    else:\n",
    "        if a[1]=='MF':\n",
    "            a[1]='M'\n",
    "            # Since there are 12 different courses\n",
    "            a[3] = str(int(a[3])-int(uniEdit[i+15][3]))\n",
    "            a[4] = str(int(a[4])-int(uniEdit[i+15][4]))\n",
    "            a[5] = str(int(a[5])-int(uniEdit[i+15][5]))\n",
    "\n",
    "# Reformat data for 2019 and 2020\n",
    "counter = 0\n",
    "for i in range(len(uniEdit)):\n",
    "    if int(uniEdit[i][0])==2019:\n",
    "        if counter<15:\n",
    "            # We have to use vstack instead of concat or append since we are adding a 1d array to a 2d array (and since axis=0)\n",
    "            uniEdit = np.vstack((uniEdit[:i+1+counter],uniEdit[i+15+counter],uniEdit[i+1+counter:]))\n",
    "        # remove duplicates from 2019\n",
    "        elif counter==30:\n",
    "            uniEdit = np.delete(uniEdit,np.s_[i:i+15],0)\n",
    "        counter+=1\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(uniEdit)):\n",
    "    if int(uniEdit[i][0])==2020:\n",
    "        if counter<15:\n",
    "            uniEdit = np.vstack((uniEdit[:i+1+counter],uniEdit[i+15+counter],uniEdit[i+1+counter:]))\n",
    "        else:\n",
    "            print(uniEdit[i],counter)\n",
    "        counter+=1\n",
    "\n",
    "# since the last 12 rows are duplicates, we remove them\n",
    "uniEdit = np.delete(uniEdit,np.s_[-15:],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['year' 'sex' 'course' 'intake' 'enrolment' 'graduates']\n",
      " ['2005' 'M' 'Business' '346' '829' '211']\n",
      " ['2005' 'F' 'Business' '530' '1732' '495']\n",
      " ...\n",
      " ['2020' 'F' 'Sciences' '891' '3624' '1127']\n",
      " ['2020' 'M' 'Arts` Humanities and the Social Sciences' '143' '402' '107']\n",
      " ['2020' 'F' 'Arts` Humanities and the Social Sciences' '139' '412' '112']]\n"
     ]
    }
   ],
   "source": [
    "uniEdit = np.vstack((np.genfromtxt('datasets_cleaned/uni/uni_intake.csv',dtype='U64',delimiter=',')[0],uniEdit))\n",
    "print(uniEdit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete file so that savetxt does not replace chars\n",
    "os.remove('datasets_cleaned/uni/uni_intake.csv')\n",
    "# Write it back to csv in the right format now\n",
    "np.savetxt('datasets_cleaned/uni/uni_intake.csv',uniEdit,delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine intakes,enrollment and graduation data for similar courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b40f880619167c1897eb19ed28404e44ef5681baa2b94c6a6ce5dad7d6c8be5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
